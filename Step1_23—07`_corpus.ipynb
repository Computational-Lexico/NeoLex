{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyO996vg6fW0bdE+vnIibsoy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#1. Corpus\n","#Chinese"],"metadata":{"id":"of7mWC0TLyd3"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"krUjyoJbsA4E","executionInfo":{"status":"ok","timestamp":1755018264238,"user_tz":-120,"elapsed":6805,"user":{"displayName":"Lian CHEN","userId":"12677332526305816693"}},"outputId":"2631fff7-c862-4d2d-93ed-146bd4f51516"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.8.3)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.14.1)\n"]}],"source":["! pip install requests beautifulsoup4\n"]},{"cell_type":"code","source":["! pip install tqdm\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uXYh8-WixZsx","executionInfo":{"status":"ok","timestamp":1755018272874,"user_tz":-120,"elapsed":8627,"user":{"displayName":"Lian CHEN","userId":"12677332526305816693"}},"outputId":"3a259808-8b99-4059-befb-9fa4051bd5f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"]}]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","from datetime import datetime, timedelta\n","import time\n","import csv\n","from tqdm import tqdm  # æ–°å¢å¯¼å…¥\n","\n","start_date = datetime(2015, 1, 1)\n","end_date = datetime(2025, 7, 1)\n","\n","headers = {\n","    'User-Agent': 'Mozilla/5.0'\n","}\n","\n","articles_data = []\n","\n","#  å¼€å§‹è®¡æ—¶\n","start_time = time.time()\n","\n","#  æ„å»ºæ—¥æœŸåˆ—è¡¨ä¾› tqdm ä½¿ç”¨\n","total_days = (end_date - start_date).days + 1\n","date_list = [start_date + timedelta(days=i) for i in range(total_days)]\n","\n","#  ä½¿ç”¨ tqdm åŒ…è£… date_list ä»¥æ˜¾ç¤ºè¿›åº¦æ¡\n","for current_date in tqdm(date_list, desc=\"æŠ“å–è¿›åº¦\"):\n","    date_str = current_date.strftime(\"%Y-%m/%d\")\n","    base_url = f\"http://paper.people.com.cn/rmrb/html/{date_str}/nbs.D110000renmrb_01.htm\"\n","\n","    try:\n","        res = requests.get(base_url, headers=headers, timeout=10)\n","        res.encoding = 'utf-8'\n","        if res.status_code == 200:\n","            soup = BeautifulSoup(res.text, 'html.parser')\n","            page_links = soup.select(\"div#pageList a\")\n","            for page in page_links:\n","                page_href = page.get('href')\n","                if not page_href:\n","                    continue\n","                page_url = f\"http://paper.people.com.cn/rmrb/html/{date_str}/{page_href}\"\n","                try:\n","                    page_res = requests.get(page_url, headers=headers, timeout=10)\n","                    page_res.encoding = 'utf-8'\n","                    page_soup = BeautifulSoup(page_res.text, 'html.parser')\n","                    article_links = page_soup.select(\"div.news a\")\n","                    for a in article_links:\n","                        href = a.get('href')\n","                        if not href:\n","                            continue\n","                        article_url = f\"http://paper.people.com.cn/rmrb/html/{date_str}/{href}\"\n","                        try:\n","                            article_res = requests.get(article_url, headers=headers, timeout=10)\n","                            article_res.encoding = 'utf-8'\n","                            article_soup = BeautifulSoup(article_res.text, 'html.parser')\n","                            title = article_soup.select_one(\"h1\").get_text(strip=True) if article_soup.select_one(\"h1\") else \"\"\n","                            subtitle = article_soup.select_one(\"h2\").get_text(strip=True) if article_soup.select_one(\"h2\") else \"\"\n","                            content_div = article_soup.select_one(\"div#ozoom\")\n","                            content = content_div.get_text(separator=\"\\n\").strip() if content_div else \"\"\n","                            articles_data.append([\n","                                current_date.strftime(\"%Y-%m-%d\"),\n","                                title,\n","                                subtitle,\n","                                content,\n","                                article_url\n","                            ])\n","                        except Exception:\n","                            continue\n","                except Exception:\n","                    continue\n","        time.sleep(1)  # æ¯å¤©è¯·æ±‚é—´éš”1ç§’ï¼Œé¿å…è¢«å°IP\n","    except Exception:\n","        pass\n","\n","# ä¿å­˜ä¸ºCSVæ–‡ä»¶\n","with open(\"people_daily_2015_2025.csv\", \"w\", encoding=\"utf-8-sig\", newline=\"\") as f:\n","    writer = csv.writer(f)\n","    writer.writerow([\"æ—¥æœŸ\", \"æ ‡é¢˜\", \"å‰¯æ ‡é¢˜\", \"æ­£æ–‡\", \"ç½‘å€\"])\n","    writer.writerows(articles_data)\n","\n","print(\" æŠ“å–å®Œæˆï¼Œå…±æ”¶é›†æ–‡ç« æ•°ï¼š\", len(articles_data))\n","\n","# â± æ˜¾ç¤ºæ€»è€—æ—¶\n","end_time = time.time()\n","total_time = end_time - start_time\n","minutes = int(total_time // 60)\n","seconds = int(total_time % 60)\n","print(f\"â± æ€»è€—æ—¶ï¼š{minutes} åˆ† {seconds} ç§’\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":392},"id":"KfUfNrL_xgY0","outputId":"a321798c-5dec-4466-93f5-af1115040056","executionInfo":{"status":"error","timestamp":1755018740910,"user_tz":-120,"elapsed":6417,"user":{"displayName":"Lian CHEN","userId":"12677332526305816693"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["æŠ“å–è¿›åº¦:   9%|â–‰         | 362/3835 [07:47<1:14:47,  1.29s/it]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3995797430.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1393\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["#1) Quotidien du Peuple\n","\n","2022-2025\n","http://paper.people.com.cn/rmrb/pc/layout/202507/23/node_01.html\n","\n","\n","#2) https://www.google.com/advanced_search?q=site:thepaper.cn+2015&client=firefox-b-d&sca_esv=4d1e52ecd0f51357&sxsrf=AE3TifOp3VsAjjic0H6D16Q26gmvMKT8dQ:1753550785198&tbas=0&biw=1232&bih=728&dpr=2\n","\n","\n","# 3) http://www.people.com.cn/\n"],"metadata":{"id":"Ls8QfVsRMblR"}},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import csv\n","\n","# ç›®æ ‡ç½‘é¡µ\n","url = \"https://paper.people.com.cn/rmrb/html/2024-07/01/nw.D110000renmrb_20240701_6-20.htm\"\n","headers = {\n","    'User-Agent': 'Mozilla/5.0'\n","}\n","\n","# å‘èµ·è¯·æ±‚\n","res = requests.get(url, headers=headers)\n","res.encoding = 'utf-8'\n","\n","if res.status_code == 200:\n","    soup = BeautifulSoup(res.text, 'html.parser')\n","\n","    # æå–å­—æ®µ\n","    title = soup.select_one(\"h1\").get_text(strip=True) if soup.select_one(\"h1\") else \"\"\n","    subtitle = soup.select_one(\"h2\").get_text(strip=True) if soup.select_one(\"h2\") else \"\"\n","    title = f\"{title}: {subtitle}\" if subtitle else title\n","\n","    # ä½œè€…å¯èƒ½åœ¨ <div class=\"edit\">ï¼Œæœ‰æ—¶åœ¨æ­£æ–‡é‡Œ\n","    author_tag = soup.select_one(\"div.edit\")\n","    author = author_tag.get_text(strip=True).replace(\"ç¼–è¾‘ï¼š\", \"\") if author_tag else \"\"\n","\n","    # æ—¥æœŸä» URL è·å–\n","    date = \"2022-07-01\"\n","\n","    # æ­£æ–‡\n","    content_div = soup.select_one(\"div#ozoom\")\n","    content = content_div.get_text(separator=\"\\n\").strip() if content_div else \"\"\n","\n","    # æ¥æºï¼ˆå›ºå®šï¼‰\n","    source = \"People's Daily (Renmin Ribao)\"\n","\n","    # å†™å…¥ CSV æ–‡ä»¶\n","    with open(\"quotidienne87.csv\", \"w\", encoding=\"utf-8-sig\", newline=\"\") as csvfile:\n","        writer = csv.writer(csvfile)\n","        writer.writerow([\"author\", \"title\", \"date\", \"content\", \"source\"])\n","        writer.writerow([author, title, date, content, source])\n","\n","    print(\" æˆåŠŸä¿å­˜ä¸º 'quotidienne6.csv'\")\n","else:\n","    print(f\" è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{res.status_code}\")\n"],"metadata":{"id":"bpWV9Emor9Tg","colab":{"base_uri":"https://localhost:8080/","height":110},"executionInfo":{"status":"error","timestamp":1755101346198,"user_tz":-120,"elapsed":56,"user":{"displayName":"Lian CHEN","userId":"12677332526305816693"}},"outputId":"f84183e6-04e2-4b2c-dadc-7170ec7e1f51"},"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"unterminated string literal (detected at line 6) (ipython-input-614328957.py, line 6)","traceback":["\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-614328957.py\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    url = \"http://www.people.com.cn/n/2015/0921/c347079-27612558.html\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 6)\n"]}]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","\n","# ç›®æ ‡ URL\n","url = \"http://www.people.com.cn/n1/2015/1214/c393876-27927336.html\"\n","\n","# è¯·æ±‚ç½‘é¡µ\n","headers = {\"User-Agent\": \"Mozilla/5.0\"}\n","response = requests.get(url, headers=headers)\n","response.encoding = \"utf-8\"  # ç¡®ä¿ä¸­æ–‡ä¸ä¼šä¹±ç \n","\n","# è§£æ HTML\n","soup = BeautifulSoup(response.text, \"html.parser\")\n","\n","# ===== æå–æ ‡é¢˜ =====\n","title_tag = soup.find(\"h1\", id=\"p_title\")\n","title = title_tag.get_text(strip=True) if title_tag else \"\"\n","\n","# ===== æå–ä½œè€… =====\n","author_tag = soup.find(\"i\", id=\"p_editor\")\n","author = author_tag.get_text(strip=True) if author_tag else \"\"\n","\n","# ===== æå–æ—¥æœŸ =====\n","date_tag = soup.find(\"span\", id=\"p_publishtime\")\n","date = date_tag.get_text(strip=True) if date_tag else \"\"\n","\n","# ===== æå–æ­£æ–‡å†…å®¹ =====\n","content_div = soup.find(\"div\", id=\"p_content\")\n","paragraphs = content_div.find_all(\"p\") if content_div else []\n","content = \"\\n\".join(p.get_text(strip=True) for p in paragraphs)\n","\n","# ===== ä¿å­˜æ•°æ®åˆ° CSV =====\n","data = [{\n","    \"author\": author,\n","    \"title\": title,\n","    \"date\": date,\n","    \"content\": content,\n","    \"url\": url\n","}]\n","\n","df = pd.DataFrame(data)\n","df.to_csv(\"peuple2015_6.csv\", index=False, encoding=\"utf-8-sig\")\n","\n","print(\"å·²å®ŒæˆæŠ“å–ï¼Œå·²ä¿å­˜ä¸º peuple2016.csv\")\n"],"metadata":{"id":"B4uVfShOW8ff","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755101404472,"user_tz":-120,"elapsed":537,"user":{"displayName":"Lian CHEN","userId":"12677332526305816693"}},"outputId":"7c4134c3-557c-4ea7-f32a-60eaf71d4dba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["å·²å®ŒæˆæŠ“å–ï¼Œå·²ä¿å­˜ä¸º peuple2016.csv\n"]}]},{"cell_type":"code","source":["#2016\n","\n","\n","import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","\n","# ç›®æ ‡ URL\n","url = \"http://www.people.com.cn/n1/2016/0901/c397545-28684604.html\"\n","\n","# è¯·æ±‚ç½‘é¡µ\n","headers = {\"User-Agent\": \"Mozilla/5.0\"}\n","response = requests.get(url, headers=headers)\n","response.encoding = \"utf-8\"  # ç¡®ä¿ä¸­æ–‡ä¸ä¼šä¹±ç \n","\n","# è§£æ HTML\n","soup = BeautifulSoup(response.text, \"html.parser\")\n","\n","# ===== æå–æ ‡é¢˜ =====\n","title_tag = soup.find(\"h1\")\n","title = title_tag.get_text(strip=True) if title_tag else \"\"\n","\n","# ===== æå–æ—¥æœŸ =====\n","# æ—¥æœŸåœ¨ <div class=\"fl\"> é‡Œ\n","date_tag = soup.find(\"div\", class_=\"fl\")\n","date = date_tag.get_text(strip=True) if date_tag else \"\"\n","\n","# ===== æå–ä½œè€… =====\n","# ä½œè€…åœ¨ <div class=\"edit clearfix\"> é‡Œ\n","author_tag = soup.find(\"div\", class_=\"edit clearfix\")\n","author = author_tag.get_text(strip=True) if author_tag else \"\"\n","\n","# ===== æå–æ­£æ–‡å†…å®¹ =====\n","content_div = soup.find(\"div\", id=\"rwb_zw\")\n","content = \"\"\n","\n","if content_div:\n","    # åªå–æ‰€æœ‰ <p> æ ‡ç­¾çš„æ–‡æœ¬ï¼ˆè¿‡æ»¤æ‰å›¾ç‰‡è¯´æ˜å’Œç©ºæ ‡ç­¾ï¼‰\n","    paragraphs = content_div.find_all(\"p\")\n","    content = \"\\n\".join(p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True))\n","\n","# ===== ä¿å­˜åˆ° CSV =====\n","data = [{\n","    \"author\": author,\n","    \"title\": title,\n","    \"date\": date,\n","    \"content\": content,\n","    \"url\": url\n","}]\n","\n","df = pd.DataFrame(data)\n","df.to_csv(\"peuple2016_17.csv\", index=False, encoding=\"utf-8-sig\")\n","\n","print(\" å·²å®ŒæˆæŠ“å–ï¼Œå·²ä¿å­˜ä¸º peuple2016.csv\")\n"],"metadata":{"id":"_STpmODMaqnc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","\n","# ç›®æ ‡ç½‘å€\n","url = \"http://www.people.com.cn/n/2015/0921/c347079-27612558.html\"\n","\n","# å‘é€è¯·æ±‚å¹¶è‡ªåŠ¨æ£€æµ‹ç¼–ç \n","headers = {\"User-Agent\": \"Mozilla/5.0\"}\n","response = requests.get(url, headers=headers)\n","response.encoding = response.apparent_encoding  # è‡ªåŠ¨è¯†åˆ«ç¼–ç ï¼Œé˜²æ­¢ä¹±ç \n","\n","# ç”¨ BeautifulSoup è§£æ\n","soup = BeautifulSoup(response.text, \"html.parser\")\n","\n","# =========  æå–æ ‡é¢˜ =========\n","title = \"\"\n","title_tag = soup.find(\"h1\", id=\"p_title\")\n","if title_tag:\n","    title = title_tag.get_text(strip=True)\n","\n","# ========= æå–æ—¥æœŸ =========\n","date = \"\"\n","date_tag = soup.find(\"span\", id=\"p_publishtime\")\n","if date_tag:\n","    date = date_tag.get_text(strip=True)\n","\n","# ========= æå–ä½œè€… =========\n","author = \"\"\n","author_tag = soup.find(\"div\", class_=\"edit\")  # æ³¨æ„è¿™é‡Œæœ‰æ—¶æ˜¯ class=\"edit clearfix\"\n","if author_tag:\n","    author = author_tag.get_text(strip=True)\n","\n","# ========= æå–æ­£æ–‡å†…å®¹ =========\n","content = \"\"\n","content_div = soup.find(\"div\", id=\"p_content\")\n","if content_div:\n","    paragraphs = content_div.find_all(\"p\")\n","    content = \"\\n\".join(p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True))\n","\n","# ========= ä¿å­˜åˆ° CSV =========\n","data = [{\n","    \"author\": author,\n","    \"title\": title,\n","    \"date\": date,\n","    \"content\": content,\n","    \"url\": url\n","}]\n","\n","df = pd.DataFrame(data)\n","df.to_csv(\"peuple2015_23.csv\", index=False, encoding=\"utf-8-sig\")  # ç”¨ utf-8-sig ç¡®ä¿ Excel æ‰“å¼€ä¸ä¹±ç \n","\n","# æ‰“å°ç»“æœéªŒè¯\n","print(f\"æŠ“å–å®Œæˆï¼\\næ ‡é¢˜: {title}\\næ—¥æœŸ: {date}\\nä½œè€…: {author}\\nå†…å®¹é¢„è§ˆ: {content[:60]}...\")\n"],"metadata":{"id":"QtqhkJC-c69u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755101784008,"user_tz":-120,"elapsed":1003,"user":{"displayName":"Lian CHEN","userId":"12677332526305816693"}},"outputId":"535769a5-84f5-452c-a01e-9d1e39d5c9a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["æŠ“å–å®Œæˆï¼\n","æ ‡é¢˜: æ”¿åŠ¡å¾®åšåŠå®äº‹æ’è¡Œæ¦œ59ï¼š@ä¸­å›½ä¿é™©æŠ¥Â è·èµæœ€å¤š\n","æ—¥æœŸ: 2015å¹´09æœˆ21æ—¥09:27\n","ä½œè€…: (è´£ç¼–ï¼šå¼ å¨…å–ƒã€æå°ç‚œ)\n","å†…å®¹é¢„è§ˆ: äººæ°‘ç½‘åŒ—äº¬9æœˆ21æ—¥ç”µï¼ˆå¼ å¨…å–ƒ å®ä¹ ç”Ÿç†Šæ·ï¼‰9æœˆ21æ—¥ï¼Œåœ¨äººæ°‘å¾®åšâ€œå¯¹è¯å®˜å¾®â€æ¨å‡ºçš„ã€Šå…¨å›½æ”¿åŠ¡å¾®åšåŠå®äº‹æ’è¡Œæ¦œã€‹ç¬¬59æœŸ...\n"]}]},{"cell_type":"code","source":["#2018\n","\n","import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","\n","# ç›®æ ‡ç½‘å€\n","url = \"http://www.people.com.cn/n1/2018/0303/c32306-29845828.html\"\n","\n","# å‘é€è¯·æ±‚å¹¶è‡ªåŠ¨æ£€æµ‹ç¼–ç \n","headers = {\"User-Agent\": \"Mozilla/5.0\"}\n","response = requests.get(url, headers=headers)\n","response.encoding = response.apparent_encoding  # è‡ªåŠ¨è¯†åˆ«ç¼–ç ï¼Œé˜²æ­¢ä¹±ç \n","\n","# ç”¨ BeautifulSoup è§£æ\n","soup = BeautifulSoup(response.text, \"html.parser\")\n","\n","# =========  æå–æ ‡é¢˜ =========\n","title = \"\"\n","title_tag = soup.find(\"h1\", id=\"p_title\")\n","if title_tag:\n","    title = title_tag.get_text(strip=True)\n","\n","# ========= æå–æ—¥æœŸ =========\n","date = \"\"\n","date_tag = soup.find(\"i\", id=\"p_publishtime\")   #  è¿™é‡Œæ”¹æˆ<i>ï¼Œä¸æ˜¯<span>\n","if date_tag:\n","    date = date_tag.get_text(strip=True)\n","\n","# ========= æå–ä½œè€… =========\n","author = \"\"\n","author_tag = soup.find(\"div\", id=\"p_editor\")   # äººæ°‘ç½‘ä½œè€…æ ‡ç­¾æ˜¯id=\"p_editor\"\n","if author_tag:\n","    author = author_tag.get_text(strip=True).replace(\"(è´£ç¼–ï¼š\", \"\").replace(\")\", \"\")\n","\n","# ========= æå–æ­£æ–‡å†…å®¹ =========\n","content = \"\"\n","content_div = soup.find(\"div\", id=\"p_content\")\n","if content_div:\n","    paragraphs = content_div.find_all(\"p\")\n","    content = \"\\n\".join(p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True))\n","\n","# ========= ä¿å­˜åˆ° CSV =========\n","data = [{\n","    \"author\": author,\n","    \"title\": title,\n","    \"date\": date,\n","    \"content\": content,\n","    \"source\": url\n","}]\n","\n","df = pd.DataFrame(data)\n","df.to_csv(\"peuple2018_4.csv\", index=False, encoding=\"utf-8-sig\")  # ç”¨ utf-8-sigï¼ŒExcel æ‰“å¼€ä¸ä¹±ç \n","\n","# æ‰“å°ç»“æœéªŒè¯\n","print(f\"æŠ“å–å®Œæˆï¼\\næ ‡é¢˜: {title}\\næ—¥æœŸ: {date}\\nä½œè€…: {author}\\nå†…å®¹é¢„è§ˆ: {content[:60]}...\")\n","\n"],"metadata":{"id":"ljTHBgVqQr0n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","\n","# ç›®æ ‡ç½‘å€\n","url = \"http://www.people.com.cn/n1/2019/0304/c32306-30956836.html\"\n","\n","# è¯·æ±‚å¤´ï¼ˆæ¨¡æ‹Ÿæµè§ˆå™¨ï¼Œé¿å…è¢«æ‹¦æˆªæˆ–è¿”å›è·³è½¬é¡µï¼‰\n","headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"}\n","\n","# å‘é€è¯·æ±‚\n","response = requests.get(url, headers=headers)\n","response.encoding = response.apparent_encoding  # è‡ªåŠ¨è¯†åˆ«ç¼–ç ï¼Œé˜²æ­¢ä¹±ç \n","\n","# ğŸ› ï¸ è°ƒè¯•ï¼šæ‰“å° URL å’Œ HTML å‰ 1000 ä¸ªå­—ç¬¦ï¼Œæ£€æŸ¥æ˜¯å¦æ‹¿åˆ°æ­£ç¡®é¡µé¢\n","print(\"å®é™…æŠ“å–çš„ URL:\", response.url)\n","print(\"HTML å‰ 1000 å­—ç¬¦:\\n\", response.text[:1000])\n","\n","# è§£æ HTML\n","soup = BeautifulSoup(response.text, \"html.parser\")\n","\n","# ========= æå–æ ‡é¢˜ =========\n","title_tag = soup.find(\"h1\", id=\"p_title\") or soup.find(\"h1\")  # ä¼˜å…ˆæ‰¾ id=\"p_title\"ï¼Œå¦åˆ™æ‰¾ h1\n","title = title_tag.get_text(strip=True) if title_tag else \"\"\n","print(\"æ ‡é¢˜:\", title)\n","\n","# ========= æå–æ—¥æœŸ =========\n","date_tag = soup.find(\"div\", class_=\"col-1-1 fl\")\n","date = date_tag.get_text(strip=True).split(\"|\")[0] if date_tag else \"\"\n","print(\"æ—¥æœŸ:\", date)\n","\n","# ========= æå–ä½œè€… =========\n","author_tag = soup.find(\"div\", class_=\"edit cf\")\n","author = author_tag.get_text(strip=True).replace(\"(è´£ç¼–ï¼š\", \"\").replace(\")\", \"\") if author_tag else \"\"\n","print(\"ä½œè€…:\", author)\n","\n","# ========= æå–æ­£æ–‡ =========\n","content = \"\"\n","content_div = soup.find(\"div\", class_=\"rm_txt_con cf\")\n","if content_div:\n","    paragraphs = content_div.find_all(\"p\")\n","    content = \"\\n\".join(p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True))\n","print(\"æ­£æ–‡å‰ 60 å­—:\", content[:60])\n","\n","# ========= ä¿å­˜åˆ° CSV =========\n","data = [{\n","    \"author\": author,\n","    \"title\": title,\n","    \"date\": date,\n","    \"content\": content,\n","    \"source\": url\n","}]\n","\n","df = pd.DataFrame(data)\n","df.to_csv(\"peuple2019_18.csv\", index=False, encoding=\"utf-8-sig\")  # ç”¨ utf-8-sigï¼ŒExcel æ‰“å¼€ä¸ä¹±ç \n","\n","print(\"æŠ“å–å®Œæˆï¼å·²ç”Ÿæˆ peuple2019.csv \")\n"],"metadata":{"id":"63dDGjtVX0PH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","\n","# ç›®æ ‡ç½‘å€\n","url = \"http://www.people.com.cn/n1/2019/0306/c425620-30960965.html\"\n","\n","# è¯·æ±‚å¤´ï¼ˆæ¨¡æ‹Ÿæµè§ˆå™¨ï¼‰\n","headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"}\n","\n","# å‘é€è¯·æ±‚\n","response = requests.get(url, headers=headers)\n","response.encoding = response.apparent_encoding  # è‡ªåŠ¨è¯†åˆ«ç¼–ç ï¼Œé¿å…ä¹±ç \n","\n","# ğŸ› ï¸ è°ƒè¯•è¾“å‡ºï¼ˆå¯æ³¨é‡Šï¼‰\n","print(\"å®é™…æŠ“å–çš„ URL:\", response.url)\n","print(\"HTML å‰ 500 å­—ç¬¦:\\n\", response.text[:500])\n","\n","# è§£æ HTML\n","soup = BeautifulSoup(response.text, \"html.parser\")\n","\n","# ========= æå–æ ‡é¢˜ =========\n","title_tag = soup.find(\"h1\", id=\"p_title\")\n","title = title_tag.get_text(strip=True) if title_tag else \"\"\n","print(\"æ ‡é¢˜:\", title)\n","\n","# ========= æå–æ—¥æœŸ =========\n","date_tag = soup.find(\"i\", id=\"p_publishtime\")\n","date = date_tag.get_text(strip=True) if date_tag else \"\"\n","print(\"æ—¥æœŸ:\", date)\n","\n","# ========= æå–ä½œè€… =========\n","author_tag = soup.find(\"div\", id=\"p_editor\")\n","author = author_tag.get_text(strip=True).replace(\"(è´£ç¼–ï¼š\", \"\").replace(\")\", \"\") if author_tag else \"\"\n","print(\"ä½œè€…:\", author)\n","\n","# ========= æå–æ­£æ–‡ =========\n","content = \"\"\n","content_div = soup.find(\"div\", id=\"p_content\")\n","if content_div:\n","    paragraphs = content_div.find_all(\"p\")\n","    content = \"\\n\".join(\n","        p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True)\n","    )\n","print(\"æ­£æ–‡å‰ 60 å­—:\", content[:60])\n","\n","# ========= ä¿å­˜åˆ° CSV =========\n","data = [{\n","    \"author\": author,\n","    \"title\": title,\n","    \"date\": date,\n","    \"content\": content,\n","    \"source\": url\n","}]\n","\n","df = pd.DataFrame(data)\n","df.to_csv(\"peuple2019_20.csv\", index=False, encoding=\"utf-8-sig\")  # ç”¨ utf-8-sigï¼ŒExcel æ‰“å¼€ä¸ä¹±ç \n","\n","print(\" æŠ“å–å®Œæˆï¼å·²ç”Ÿæˆ peuple2019.csv \")\n"],"metadata":{"id":"R_nbERdge2Tr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import csv\n","\n","# ç›®æ ‡ç½‘å€\n","url = \"http://world.people.com.cn/n1/2024/0206/c1002-40174467.html\"\n","\n","# è¯·æ±‚ç½‘é¡µ\n","response = requests.get(url)\n","response.encoding = response.apparent_encoding  # è‡ªåŠ¨æ£€æµ‹çœŸå®ç¼–ç \n","html = response.text\n","\n","# è§£æ HTML\n","soup = BeautifulSoup(html, \"html.parser\")\n","\n","# === æŠ“å–æ ‡é¢˜ ===\n","\n","title = \"æ‘©å°”å¤šç“¦é¦–å‘é¾™å¹´ç”Ÿè‚–é‚®ç¥¨\"\n","\n","# === æŠ“å–ä½œè€… (è´£ç¼–) ===\n","# æ³¨æ„ï¼šæœ‰æ—¶ä¼šæœ‰å¤šä¸ª edit cfï¼Œæ­£æ–‡åº•éƒ¨çš„æ‰æ˜¯ä½œè€…\n","author_divs = soup.find_all(\"div\", class_=\"edit cf\")\n","author = author_divs[-1].get_text(strip=True).replace(\"è´£ç¼–ï¼š\", \"\") if author_divs else \"\"\n","\n","# ===  æŠ“å–æ—¥æœŸå’Œæ¥æº ===\n","date_div = soup.find(\"div\", class_=\"col-1-1 fl\")\n","date_text = \"\"\n","source = \"\"\n","if date_div:\n","    date_text = date_div.get_text(strip=True).split(\"|\")[0].strip()\n","    source_a = date_div.find(\"a\")\n","    source = source_a.get_text(strip=True) if source_a else \"\"\n","\n","# === æŠ“å–æ­£æ–‡å†…å®¹ ===\n","content_div = soup.find(\"div\", class_=\"rm_txt_con cf\")\n","paragraphs = []\n","if content_div:\n","    for p in content_div.find_all(\"p\"):\n","        txt = p.get_text(strip=True)\n","        if txt:\n","            paragraphs.append(txt)\n","content = \"\\n\".join(paragraphs)\n","\n","# === ä¿å­˜åˆ° CSV ===\n","with open(\"peuple2024_1.csv\", \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n","    writer = csv.writer(f)\n","    writer.writerow([\"author\", \"title\", \"date\", \"content\", \"source\"])\n","    writer.writerow([author, title, date_text, content, source])\n","\n","print(\"æŠ“å–å®Œæˆï¼Œå·²ä¿å­˜åˆ° peuple2023_1.csv\")\n","print(f\"æ ‡é¢˜ï¼š{title}\")\n","print(f\"æ—¥æœŸï¼š{date_text}\")\n","print(f\"æ¥æºï¼š{source}\")\n","print(f\"ä½œè€…ï¼š{author}\")\n"],"metadata":{"id":"blu4RL-hG26l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#ä¸‹è½½åŒ…\n","\n","\n","import zipfile\n","import os\n","\n","zip_path = \"/content/peuple_all_csv.zip\"\n","with zipfile.ZipFile(zip_path, 'w') as zipf:\n","    for file in os.listdir(\"/content\"):\n","        if file.endswith(\".csv\") and file.startswith(\"peuple2015_\"):\n","            zipf.write(os.path.join(\"/content\", file), arcname=file)\n"],"metadata":{"id":"yWZA7pb5ZO3s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","files.download(\"/content/peuple_all_csv.zip\")\n"],"metadata":{"id":"KZOybUt9ZSqN","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1755101797433,"user_tz":-120,"elapsed":33,"user":{"displayName":"Lian CHEN","userId":"12677332526305816693"}},"outputId":"a2678f20-2e1c-41a8-a94b-8342a62197f3"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_4c7996e2-7cd3-4aac-aeaa-3488b7ea0627\", \"peuple_all_csv.zip\", 44579)"]},"metadata":{}}]},{"cell_type":"markdown","source":["#penbaixinwei\n"],"metadata":{"id":"W_teGjb2QG4B"}},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","\n","# è®¾ç½® URL\n","url = \"https://www.thepaper.cn/newsDetail_forward_31158236\"\n","\n","# è¯·æ±‚å¤´\n","headers = {\n","    \"User-Agent\": \"Mozilla/5.0\"\n","}\n","\n","# è·å–ç½‘é¡µå†…å®¹\n","response = requests.get(url, headers=headers)\n","response.encoding = 'utf-8'\n","soup = BeautifulSoup(response.text, \"html.parser\")\n","\n","# æå–æ ‡é¢˜\n","title_tag = soup.find(\"h1\", class_=\"index_title__B8mhI\")\n","title = title_tag.get_text(strip=True) if title_tag else \"\"\n","\n","# æå–ä½œè€…ï¼ˆé€šå¸¸åœ¨æ ‡é¢˜ä¸Šæ–¹æˆ–ä¸‹æ–¹çš„æŸä¸ª <div> ä¸­ï¼ŒåŒ…å«â€œæ¾æ¹ƒæ–°é—»è®°è€…â€ï¼‰\n","author = \"\"\n","for div in soup.find_all(\"div\"):\n","    if div.text.strip().startswith(\"æ¾æ¹ƒæ–°é—»è®°è€…\"):\n","        author = div.text.strip().replace(\"æ¾æ¹ƒæ–°é—»è®°è€…\", \"\").strip()\n","        break\n","\n","# æå–æ—¥æœŸï¼ˆç¬¬ä¸€ä¸ªåŒ…å«æ—¶é—´æ ¼å¼çš„ <span>ï¼‰\n","date = \"\"\n","for span in soup.find_all(\"span\"):\n","    if span.text.strip().startswith(\"20\") and \":\" in span.text:\n","        date = span.text.strip()\n","        break\n","\n","# æå–æ­£æ–‡å†…å®¹\n","content_div = soup.find(\"div\", class_=\"index_cententWrap__Jv8jK\")\n","paragraphs = content_div.find_all(\"p\") if content_div else []\n","content = \"\\n\".join([p.get_text(strip=True) for p in paragraphs])\n","\n","# æ„é€ æ•°æ®\n","data = [[author, title, date, content, url]]\n","df = pd.DataFrame(data, columns=[\"author\", \"title\", \"date\", \"content\", \"source\"])\n","\n","# ä¿å­˜ä¸º CSV\n","df.to_csv(\"pengpai2020_140.csv\", index=False, encoding=\"utf-8-sig\")\n","print(\" æŠ“å–å®Œæˆï¼Œä¿å­˜ pengpai2015_1.csv\")\n"],"metadata":{"id":"orYgoXbaPUFx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import csv\n","\n","# ç›®æ ‡ URL\n","url = \"https://www.thepaper.cn/newsDetail_forward_1351726\"\n","\n","# å‘é€è¯·æ±‚\n","headers = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n","}\n","response = requests.get(url, headers=headers)\n","response.encoding = \"utf-8\"  # æ¾æ¹ƒæ–°é—»ç”¨utf-8ç¼–ç \n","\n","# è§£æ HTML\n","soup = BeautifulSoup(response.text, \"html.parser\")\n","\n","# æå– author\n","author_tag = soup.find(\"div\", string=lambda t: t and \"æ¾æ¹ƒæ–°é—»è®°è€…\" in t)\n","author = author_tag.get_text(strip=True) if author_tag else \"\"\n","\n","# æå– title\n","title_tag = soup.find(\"h1\", class_=\"index_title__B8mhI\")\n","title = title_tag.get_text(strip=True) if title_tag else \"\"\n","\n","# æå– date\n","date_tag = soup.find(\"span\")\n","date = date_tag.get_text(strip=True) if date_tag else \"\"\n","\n","# æå– content\n","content_div = soup.find(\"div\", class_=\"index_cententWrap__Jv8jK\")\n","if content_div:\n","    # å»æ‰å¤šä½™æ ‡ç­¾ï¼Œåªä¿ç•™çº¯æ–‡æœ¬\n","    content = \"\\n\".join(p.get_text(strip=True) for p in content_div.find_all(\"p\"))\n","else:\n","    content = \"\"\n","\n","# ä¿å­˜åˆ° CSV\n","csv_filename = \"pengpai2015_5.csv\"\n","with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n","    writer = csv.writer(f)\n","    writer.writerow([\"author\", \"title\", \"date\", \"content\", \"url\"])\n","    writer.writerow([author, title, date, content, url])\n","\n","print(f\"æ•°æ®å·²ä¿å­˜åˆ° {csv_filename}\")\n"],"metadata":{"id":"B2u9CS0nzEh-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import csv\n","\n","# ç›®æ ‡ç½‘é¡µ\n","url = \"https://www.thepaper.cn/newsDetail_forward_8250801\"\n","\n","# è¯·æ±‚ç½‘é¡µ\n","response = requests.get(url)\n","response.encoding = \"utf-8\"\n","soup = BeautifulSoup(response.text, \"html.parser\")\n","\n","# 1ï¸æ ‡é¢˜\n","title_tag = soup.find(\"h1\", class_=\"index_title__B8mhI\")\n","title = title_tag.get_text(strip=True) if title_tag else \"\"\n","\n","# 2ï¸æ—¥æœŸï¼ˆé€šå¸¸æ˜¯ç¬¬ä¸€ä¸ª spanï¼Œæ²¡æœ‰â€œæ¥æºâ€å­—æ ·ï¼‰\n","date_tag = soup.find(\"span\", string=lambda t: t and \"æ¥æº\" not in t)\n","date = date_tag.get_text(strip=True) if date_tag else \"\"\n","\n","# 3ï¸ä½œè€…ï¼ˆæŸ¥æ‰¾åŒ…å«â€œæ¥æºâ€çš„ spanï¼Œå¹¶å»æ‰å‰ç¼€â€œæ¥æºï¼šâ€ï¼‰\n","author_tag = soup.find(\"span\", string=lambda t: t and \"æ¥æº\" in t)\n","author = author_tag.get_text(strip=True).replace(\"æ¥æºï¼š\", \"\") if author_tag else \"\"\n","\n","# 4ï¸æ­£æ–‡ï¼ˆæ‰€æœ‰ <p> é‡Œçš„æ–‡å­—ï¼‰\n","content_div = soup.find(\"div\", class_=\"index_cententWrap__Jv8jK\")\n","content = \"\"\n","if content_div:\n","    paragraphs = content_div.find_all(\"p\")\n","    content = \"\\n\".join([p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True)])\n","\n","# 5ï¸å†™å…¥ CSV\n","csv_file = \"pengpai2020_19.csv\"\n","with open(csv_file, \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n","    writer = csv.DictWriter(f, fieldnames=[\"author\", \"title\", \"date\", \"content\", \"url\"])\n","    writer.writeheader()\n","    writer.writerow({\n","        \"author\": author,\n","        \"title\": title,\n","        \"date\": date,\n","        \"content\": content,\n","        \"url\": url\n","    })\n","\n","print(f\"æŠ“å–å®Œæˆï¼Œå·²ä¿å­˜åˆ° {csv_file}\")\n"],"metadata":{"id":"m4z8XoXeZmLd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","\n","# è¦æŠ“å–çš„ç½‘é¡µ\n","url = \"https://www.thepaper.cn/newsDetail_forward_29761657\"\n","\n","# è¯·æ±‚ç½‘é¡µ\n","headers = {\"User-Agent\": \"Mozilla/5.0\"}\n","response = requests.get(url, headers=headers)\n","response.encoding = \"utf-8\"\n","\n","# ç”¨ BeautifulSoup è§£æ\n","soup = BeautifulSoup(response.text, \"html.parser\")\n","\n","# ===== æŠ“å–æ ‡é¢˜ =====\n","title_tag = soup.find(\"h1\", class_=\"index_title__B8mhI\")\n","title = title_tag.get_text(strip=True) if title_tag else \"\"\n","\n","# ===== æŠ“å–ä½œè€…å’Œæ—¥æœŸ =====\n","# è·å–é¡µé¢ä¸­æ‰€æœ‰ span æ ‡ç­¾ï¼ˆé¡ºåºæ•æ„Ÿï¼‰\n","spans = soup.find_all(\"span\")\n","\n","author = \"\"\n","date = \"\"\n","\n","# éå† span æ ‡ç­¾ï¼Œæ‰¾åˆ°åŒ…å«â€œ>â€çš„ä½œä¸ºä½œè€…ï¼ŒåŒ…å«â€œ-â€çš„ä½œä¸ºæ—¥æœŸ\n","for s in spans:\n","    text = s.get_text(strip=True)\n","    if \">\" in text and author == \"\":\n","        author = text\n","    elif \"-\" in text and date == \"\":\n","        date = text\n","\n","# ===== æŠ“å–æ­£æ–‡å†…å®¹ =====\n","content_div = soup.find(\"div\", class_=\"index_cententWrap__Jv8jK\")\n","paragraphs = content_div.find_all(\"p\") if content_div else []\n","content = \"\\n\".join(p.get_text(strip=True) for p in paragraphs)\n","\n","# ===== ç”Ÿæˆ CSV =====\n","data = [{\n","    \"author\": author,\n","    \"title\": title,\n","    \"date\": date,\n","    \"content\": content,\n","    \"url\": url\n","}]\n","\n","df = pd.DataFrame(data)\n","df.to_csv(\"pengpai2024_21.csv\", index=False, encoding=\"utf-8-sig\")\n","\n","print(\"å·²å®ŒæˆæŠ“å–ï¼Œå·²ä¿å­˜ä¸º pengpai2024.csv\")\n"],"metadata":{"id":"f4s4UV_00LaC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#ä¸‹è½½åŒ…\n","\n","\n","import zipfile\n","import os\n","\n","zip_path = \"/content/pengpai_all_csv.zip\"\n","with zipfile.ZipFile(zip_path, 'w') as zipf:\n","    for file in os.listdir(\"/content\"):\n","        if file.endswith(\".csv\") and file.startswith(\"pengpai2024_\"):\n","            zipf.write(os.path.join(\"/content\", file), arcname=file)\n"],"metadata":{"id":"tfUT4rDy-q1A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","files.download(\"/content/pengpai_all_csv.zip\")\n"],"metadata":{"id":"x_RlYVwS-59I"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#3 å½­åšè´¢ç»\n","www.bloomberg.com\n","\n","\n","#https://www.google.com/advanced_search?q=site:thepaper.cn+2015&client=firefox-b-d&sca_esv=4d1e52ecd0f51357&sxsrf=AE3TifOp3VsAjjic0H6D16Q26gmvMKT8dQ:1753550785198&tbas=0&biw=1232&bih=728&dpr=2"],"metadata":{"id":"R-pY9WZb7ld6"}},{"cell_type":"markdown","source":["#4ï¼‰ ç½‘æ˜“æ–°é—»\n","#news.163.com\n"],"metadata":{"id":"96gVSCDZ8DeV"}},{"cell_type":"markdown","source":["#5ï¼‰æ–°æµªæ–°é—»ç½‘\n","# news.sina.com.cn\n"],"metadata":{"id":"88Q_z4Yu8PUQ"}},{"cell_type":"markdown","source":["#6) æ–°åç½‘ã€ä¸œæ–¹ç½‘\n","\n","#http://www.xinhuanet.com\n","\n","#http://www.eastday.com\n","\n"],"metadata":{"id":"gBvvMyjN-8N9"}},{"cell_type":"code","source":["import re\n","import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","\n","# ç›®æ ‡ç½‘é¡µURL\n","url = \"http://www.xinhuanet.com/politics/2020-07/26/c_1126287151.htm\"\n","\n","# æŠ“å–å¹¶è§£æ\n","resp = requests.get(url, timeout=15)\n","resp.encoding = \"utf-8\"\n","soup = BeautifulSoup(resp.text, \"html.parser\")\n","\n","# æ ‡é¢˜\n","title_tag = soup.select_one(\"div.h-title\")\n","title = title_tag.get_text(strip=True) if title_tag else \"\"\n","\n","# æ—¥æœŸ\n","date_tag = soup.select_one(\"span.h-time\")\n","date = date_tag.get_text(strip=True) if date_tag else \"\"\n","\n","# ä½œè€…ï¼ˆè´£ä»»ç¼–è¾‘ï¼‰\n","author = \"\"\n","pjc = soup.select_one(\"span.p-jc\")\n","if pjc:\n","    raw = pjc.get_text(\" \", strip=True)\n","    m = re.search(r\"è´£ä»»ç¼–è¾‘[:ï¼š]\\s*([^\\s\\]]+)\", raw)\n","    author = m.group(1) if m else raw\n","\n","# æ­£æ–‡\n","content = \"\"\n","content_div = soup.find(\"div\", id=\"p-detail\")\n","if content_div:\n","    # å»æ‰è§†é¢‘/è„šæœ¬ç­‰æ— å…³å—\n","    for tag in content_div.find_all([\"script\", \"style\", \"iframe\"]):\n","        tag.decompose()\n","    # å–å‡ºæ®µè½æ–‡å­—ï¼ˆå«åŠ ç²—æ®µï¼‰\n","    parts = []\n","    for tag in content_div.find_all([\"p\", \"strong\"]):\n","        txt = tag.get_text(\" \", strip=True)\n","        if txt:\n","            parts.append(txt)\n","    content = \"\\n\".join(parts).strip()\n","\n","# ç»„è£…å¹¶ä¿å­˜\n","data = [{\n","    \"author\": author,\n","    \"title\": title,\n","    \"date\": date,\n","    \"content\": content,\n","    \"url\": url\n","}]\n","df = pd.DataFrame(data)\n","\n","outname = \"xinhua2020_22.csv\"\n","df.to_csv(outname, index=False, encoding=\"utf-8-sig\")\n","print(f\"æ–‡ä»¶å·²ä¿å­˜ä¸º {outname}\")\n"],"metadata":{"id":"3znV_nNMAUDd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","\n","def normalize_space(s: str) -> str:\n","    if not s:\n","        return \"\"\n","    # å»æ‰å…¨è§’ç©ºæ ¼/ä¸é—´æ–­ç©ºæ ¼ï¼Œå‹ç¼©å¤šä½™ç©ºç™½\n","    s = s.replace(\"\\u3000\", \" \").replace(\"\\xa0\", \" \")\n","    s = re.sub(r\"[ \\t]+\", \" \", s)\n","    # å»æ‰æ ‡ç‚¹å‰çš„å¤šä½™ç©ºæ ¼\n","    s = re.sub(r\"\\s+([ï¼Œã€‚ã€â€œâ€â€˜â€™ï¼›ï¼šï¼ï¼Ÿ,.!?;:])\", r\"\\1\", s)\n","    return s.strip()\n","\n","# ä½ çš„ç›®æ ‡é¡µ\n","url = \"http://www.xinhuanet.com/world/20250527/a7997efbf96b4fe0a5e3e5731b136790/c.html\"\n","\n","# æŠ“å–é¡µé¢\n","resp = requests.get(url, timeout=20, headers={\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n","})\n","# æ–°åç½‘å¤šä¸º UTF-8ï¼Œè¿™é‡Œä½¿ç”¨ apparent_encoding å…œåº•\n","resp.encoding = resp.apparent_encoding or \"utf-8\"\n","soup = BeautifulSoup(resp.text, \"html.parser\")\n","\n","# æ ‡é¢˜ï¼š<span class=\"title\">\n","title = \"\"\n","title_tag = soup.select_one(\"span.title\")\n","if title_tag:\n","    title = normalize_space(title_tag.get_text(strip=True))\n","\n","# æ—¥æœŸï¼š<div class=\"header-time left\"><span class=\"year\"><em> 2021</em></span><span class=\"day\">02/16</span><span class=\"time\"> 14:32:57</span>\n","year = soup.select_one(\"div.header-time .year em\")\n","day = soup.select_one(\"div.header-time .day\")\n","tm  = soup.select_one(\"div.header-time .time\")\n","date = \"\"\n","if year and day and tm:\n","    y = normalize_space(year.get_text())\n","    d = normalize_space(day.get_text()).replace(\"/\", \"-\")  # 02/16 -> 02-16\n","    t = normalize_space(tm.get_text())\n","    date = f\"{y}-{d} {t}\"\n","\n","# ä½œè€…ï¼ˆè´£ä»»ç¼–è¾‘ï¼‰ï¼šé€šå¸¸åœ¨ <span class=\"editor\">ã€è´£ä»»ç¼–è¾‘:ç‹ç§€ã€‘</span>\n","author = \"\"\n","# ç›´æ¥æ‰¾æ‰€æœ‰ editorï¼Œæ‹¼å‡ºæ–‡æœ¬å†ç”¨æ­£åˆ™æå–\n","editors = soup.select(\"span.editor\")\n","if editors:\n","    raw = \" \".join(normalize_space(e.get_text(\" \", strip=True)) for e in editors)\n","    m = re.search(r\"è´£ä»»ç¼–è¾‘[:ï¼š]?\\s*([^\\sã€‘\\]]+)\", raw)\n","    if m:\n","        author = m.group(1)\n","# å…œåº•ï¼šå…¨é¡µæ‰¾â€œè´£ä»»ç¼–è¾‘â€\n","if not author:\n","    node = soup.find(string=re.compile(r\"è´£ä»»ç¼–è¾‘\"))\n","    if node:\n","        txt = normalize_space(str(node))\n","        m2 = re.search(r\"è´£ä»»ç¼–è¾‘[:ï¼š]?\\s*([^\\sã€‘\\]]+)\", txt)\n","        if m2:\n","            author = m2.group(1)\n","\n","# æ­£æ–‡ï¼š<div id=\"detail\"> ä¸‹çš„ <p>ï¼›å»æ‰ articleEdit ç­‰æ‚é¡¹\n","content = \"\"\n","detail = soup.find(\"div\", id=\"detail\")\n","if detail:\n","    # å»æ‰æ— å…³å—ï¼ˆçº é”™ã€iframe ç­‰ï¼‰\n","    for bad in detail.find_all([\"script\", \"style\", \"iframe\"]):\n","        bad.decompose()\n","    ae = detail.find(\"div\", id=\"articleEdit\")\n","    if ae:\n","        ae.decompose()\n","\n","    parts = []\n","    for p in detail.find_all(\"p\"):\n","        # è·³è¿‡åªå«å›¾ç‰‡/ç©ºè¡Œçš„æ®µè½\n","        if p.find([\"img\", \"iframe\"]):\n","            continue\n","        txt = normalize_space(p.get_text(\" \", strip=True))\n","        if not txt:\n","            continue\n","        # è¿‡æ»¤â€œçº é”™â€ç­‰å™ªå£°\n","        if \"çº é”™\" in txt or \"ç‚¹å‡»è¿›å…¥ä¸“é¢˜\" in txt:\n","            continue\n","        parts.append(txt)\n","\n","    # å»é‡å¹¶åˆå¹¶\n","    seen = set()\n","    dedup = []\n","    for t in parts:\n","        if t not in seen:\n","            seen.add(t)\n","            dedup.append(t)\n","    content = \"\\n\".join(dedup).strip()\n","\n","# ç»„è£…å¹¶ä¿å­˜\n","data = [{\n","    \"author\": author,\n","    \"title\": title,\n","    \"date\": date,\n","    \"content\": content,\n","    \"url\": url\n","}]\n","df = pd.DataFrame(data)\n","\n","outname = \"xinhua2025_26.csv\"\n","df.to_csv(outname, index=False, encoding=\"utf-8-sig\")\n","print(f\"æ–‡ä»¶å·²ä¿å­˜ä¸º {outname}\")\n","print(df.T)\n"],"metadata":{"id":"tzy76k6w7PrR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755096051367,"user_tz":-120,"elapsed":2721,"user":{"displayName":"Lian CHEN","userId":"12677332526305816693"}},"outputId":"0bd5210b-1e65-4be3-ad5c-9b61ca764c73"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["æ–‡ä»¶å·²ä¿å­˜ä¸º xinhua2025_26.csv\n","                                                         0\n","author                                                 å¼ è‰³èŠ³\n","title                    å…¨çƒè¿çº¿ï½œ2025ä¸­å¾·ï¼ˆæ¬§ï¼‰éšå½¢å† å†›è®ºå›å¼€å¹• å…±äº«ç»æµæŠ€æœ¯åˆä½œæœºé‡\n","date                                   2025-05-27 14:13:43\n","content  5æœˆ26æ—¥ï¼ŒåŒ—äº¬ä¸­å¾·äº§ä¸šåˆä½œå‘å±•è®ºå›â€”â€”2025ä¸­å¾·ï¼ˆæ¬§ï¼‰éšå½¢å† å†›è®ºå›åœ¨åŒ—äº¬é¡ºä¹‰ä¸­å¾·å›½é™…ä¼šè®®...\n","url      http://www.xinhuanet.com/world/20250527/a7997e...\n"]}]},{"cell_type":"code","source":["#å¦ä¸€ç§ç®€å•çš„å­—\n","\n","import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","\n","# ç›®æ ‡ç½‘é¡µURL\n","url = \"http://www.xinhuanet.com/world/2021-03/24/c_1127250212.htm\"\n","\n","# å‘é€HTTPè¯·æ±‚è·å–ç½‘é¡µå†…å®¹\n","response = requests.get(url)\n","response.encoding = 'utf-8'  # ç¡®ä¿ä¸­æ–‡ç¼–ç æ­£ç¡®\n","\n","# ä½¿ç”¨BeautifulSoupè§£æç½‘é¡µå†…å®¹\n","soup = BeautifulSoup(response.text, 'html.parser')\n","\n","# æå–æ ‡é¢˜\n","title = soup.find('h1', id='title').get_text(strip=True)\n","\n","# æå–æ—¥æœŸ\n","date = soup.find('span', id='pubtime').get_text(strip=True)\n","\n","# æå–å†…å®¹\n","content_div = soup.find('div', id='content')\n","content = \"\\n\".join([p.get_text(strip=True) for p in content_div.find_all('p')])\n","\n","# æå–ä½œè€…\n","author_div = soup.find('div', class_='share')\n","author = author_div.get_text(strip=True).replace(\"[è´£ä»»ç¼–è¾‘ï¼š\", \"\").replace(\"]\", \"\") if author_div else \"\"\n","\n","# URL\n","article_url = url\n","\n","# å°†æ•°æ®å­˜å‚¨ä¸ºå­—å…¸\n","data = {\n","    \"author\": [author],\n","    \"title\": [title],\n","    \"date\": [date],\n","    \"content\": [content],\n","    \"url\": [article_url]\n","}\n","\n","# å°†å­—å…¸è½¬æ¢ä¸ºDataFrame\n","df = pd.DataFrame(data)\n","\n","# ä¿å­˜ä¸ºCSVæ–‡ä»¶\n","df.to_csv('xinhua2020_1.csv', index=False, encoding='utf-8-sig')\n","\n","print(\"æ–‡ä»¶å·²ä¿å­˜ä¸º xinhua2015_1.csv\")\n"],"metadata":{"id":"JKDTiv52Htoh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#code 3\n","\n","import re\n","import requests\n","from bs4 import BeautifulSoup\n","from urllib.parse import urljoin\n","import pandas as pd\n","\n","# ç›®æ ‡ç½‘é¡µURLï¼ˆé¦–ç¯‡ï¼‰\n","url = \"http://www.xinhuanet.com/world/2021-03/24/c_1127250212.htm\"\n","\n","def fetch(url):\n","    r = requests.get(url, timeout=15)\n","    r.encoding = 'utf-8'  # æ–°åç½‘è€æ–‡åŸºæœ¬æ˜¯ utf-8\n","    return BeautifulSoup(r.text, 'html.parser')\n","\n","soup = fetch(url)\n","\n","# æ ‡é¢˜\n","title = soup.find('h1', id='title').get_text(strip=True)\n","\n","# æ—¥æœŸ\n","date = soup.find('span', class_='time').get_text(strip=True)\n","\n","# ä½œè€…ï¼ˆè´£ä»»ç¼–è¾‘ï¼‰\n","editor = soup.find('span', class_='editor')\n","author = \"\"\n","if editor:\n","    author = re.sub(r\"[\\[\\]ï¼š:\\s]*\", \"\", editor.get_text())\n","    author = author.replace(\"è´£ä»»ç¼–è¾‘\", \"\")  # åªä¿ç•™åå­—\n","\n","# --- æ­£æ–‡ï¼ˆå«åˆ†é¡µï¼‰ ---\n","def collect_content(soup, base_url):\n","    # æœ¬é¡µæ­£æ–‡\n","    article = soup.find('div', class_='article')\n","    parts = []\n","    if article:\n","        # æŠŠ p å’Œ strong çš„æ–‡å­—éƒ½å–å‡ºæ¥\n","        for tag in article.find_all(['p', 'strong']):\n","            txt = tag.get_text(\" \", strip=True)\n","            if txt:\n","                parts.append(txt)\n","\n","        # æ‰¾åˆ°åˆ†é¡µçš„é“¾æ¥ï¼ˆå¦‚ _2.htmï¼‰ï¼Œå¹¶æŠ“å–\n","        page_links = set()\n","        for a in article.find_all('a', href=True):\n","            href = a['href']\n","            if re.search(r\"_\\d+\\.htm$\", href):  # åªè¦åˆ†é¡µé¡µ\n","                full = urljoin(base_url if base_url.startswith('http') else \"http:\", href)\n","                page_links.add(full)\n","\n","        # æŒ‰åºæŠ“å–å…¶ä»–é¡µ\n","        for link in sorted(page_links):\n","            sub = fetch(link)\n","            sub_article = sub.find('div', class_='article')\n","            if sub_article:\n","                for tag in sub_article.find_all(['p', 'strong']):\n","                    txt = tag.get_text(\" \", strip=True)\n","                    if txt:\n","                        parts.append(txt)\n","\n","    # åˆå¹¶æˆä¸€æ®µæ–‡æœ¬\n","    content = \"\\n\".join(parts)\n","    # è½»åº¦æ¸…æ´—ï¼šå»æ‰å¤šä½™ç©ºç™½\n","    content = re.sub(r\"\\s+\\n\", \"\\n\", content).strip()\n","    return content\n","\n","content = collect_content(soup, url)\n","\n","# URL\n","article_url = url\n","\n","# ç»„è£…DataFrame\n","df = pd.DataFrame([{\n","    \"author\": author,\n","    \"title\": title,\n","    \"date\": date,\n","    \"content\": content,\n","    \"url\": article_url\n","}])\n","\n","# ä¿å­˜CSV\n","outname = 'xinhua2020_1.csv'\n","df.to_csv(outname, index=False, encoding='utf-8-sig')\n","print(f\"æ–‡ä»¶å·²ä¿å­˜ä¸º {outname}\")\n","\n"],"metadata":{"id":"VjmqYnqel_-F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#code 4 : nous ne parvenons pas\n","\n","import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","\n","# ç›®æ ‡ç½‘é¡µURL\n","url = \"http://www.xinhuanet.com/2021-02/16/c_1127105025.htm\"\n","\n","# å‘é€HTTPè¯·æ±‚è·å–ç½‘é¡µå†…å®¹\n","response = requests.get(url)\n","response.encoding = 'utf-8'  # é˜²æ­¢ä¸­æ–‡ä¹±ç \n","\n","# ä½¿ç”¨BeautifulSoupè§£æç½‘é¡µå†…å®¹\n","soup = BeautifulSoup(response.text, 'html.parser')\n","\n","# æå–æ ‡é¢˜\n","title = soup.find('h1', id='title').get_text(strip=True) if soup.find('h1', id='title') else ''\n","\n","# æå–æ—¥æœŸ\n","date = soup.find('span', class_='time').get_text(strip=True) if soup.find('span', class_='time') else ''\n","\n","# æå–ä½œè€…\n","author_tag = soup.find('span', class_='editor')\n","author = author_tag.get_text(strip=True).replace('[è´£ä»»ç¼–è¾‘:', '').replace(']', '') if author_tag else ''\n","\n","# æå–æ­£æ–‡å†…å®¹\n","content_div = soup.find('div', class_='article')\n","content = \"\"\n","if content_div:\n","    paragraphs = content_div.find_all('p')\n","    content = \"\\n\".join([p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True)])\n","\n","# URL\n","article_url = url\n","\n","# å°†æ•°æ®å­˜å‚¨ä¸ºå­—å…¸\n","data = {\n","    \"author\": [author],\n","    \"title\": [title],\n","    \"date\": [date],\n","    \"content\": [content],\n","    \"url\": [article_url]\n","}\n","\n","# å°†å­—å…¸è½¬æ¢ä¸ºDataFrame\n","df = pd.DataFrame(data)\n","\n","# ä¿å­˜ä¸ºCSVæ–‡ä»¶\n","df.to_csv('xinhua2020_9.csv', index=False, encoding='utf-8-sig')\n","\n","print(\"æ–‡ä»¶å·²ä¿å­˜ä¸º xinhua_2017.csv\")\n"],"metadata":{"id":"-14nperdnZDy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#ä¸‹è½½åŒ…\n","\n","\n","import zipfile\n","import os\n","\n","zip_path = \"/content/xinhua_all_csv.zip\"\n","with zipfile.ZipFile(zip_path, 'w') as zipf:\n","    for file in os.listdir(\"/content\"):\n","        if file.endswith(\".csv\") and file.startswith(\"xinhua2025_\"):\n","            zipf.write(os.path.join(\"/content\", file), arcname=file)\n"],"metadata":{"id":"zVQaeR1ZJhaB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","files.download(\"/content/xinhua_all_csv.zip\")\n"],"metadata":{"id":"H-QXQB2xJjhE","executionInfo":{"status":"ok","timestamp":1755096065668,"user_tz":-120,"elapsed":18,"user":{"displayName":"Lian CHEN","userId":"12677332526305816693"}},"colab":{"base_uri":"https://localhost:8080/","height":17},"outputId":"a418fb62-f93f-4324-e926-416899acb17e"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_72dfbd73-b9a7-42d9-9585-f34303c79483\", \"xinhua_all_csv.zip\", 76782)"]},"metadata":{}}]},{"cell_type":"markdown","source":["#3ï¼‰ å—æ–¹å‘¨æœ«\n","#https://www.google.com/advanced_search?q=site:thepaper.cn+2015&client=firefox-b-d&sca_esv=4d1e52ecd0f51357&sxsrf=AE3TifOp3VsAjjic0H6D16Q26gmvMKT8dQ:1753550785198&tbas=0&biw=1232&bih=728&dpr=2\n","\n","# https://www.infzm.com/"],"metadata":{"id":"tYm23li-XGjk"}},{"cell_type":"code","source":[],"metadata":{"id":"YSXydYgqNMIF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#ä¸‹è½½åŒ…\n","\n","\n","import zipfile\n","import os\n","\n","zip_path = \"/content/nanfang_all_csv.zip\"\n","with zipfile.ZipFile(zip_path, 'w') as zipf:\n","    for file in os.listdir(\"/content\"):\n","        if file.endswith(\".csv\") and file.startswith(\"nanfang_\"):\n","            zipf.write(os.path.join(\"/content\", file), arcname=file)\n"],"metadata":{"id":"TO-IGn3FNKWM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","files.download(\"/content/pengpai_all_csv.zip\")\n"],"metadata":{"id":"bivpD6v1NLhJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3) ZHIHU"],"metadata":{"id":"YyyWCVXfE_Tv"}},{"cell_type":"code","source":["! pip install selenium beautifulsoup4 pandas\n"],"metadata":{"id":"OO8zOG6mNMJs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#zhihu  è¯é¢˜ 2015\n","\n","from selenium import webdriver\n","from selenium.webdriver.chrome.options import Options\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import time\n","\n","# è®¾ç½®å…³é”®è¯å’Œæœç´¢åœ°å€\n","search_keyword = \"2015\"\n","search_url = f\"https://www.zhihu.com/search?q={search_keyword}&type=content\"\n","\n","# é…ç½®æµè§ˆå™¨\n","options = Options()\n","options.add_argument(\"--headless\")\n","options.add_argument(\"--no-sandbox\")\n","options.add_argument(\"--disable-dev-shm-usage\")\n","driver = webdriver.Chrome(options=options)\n","driver.get(search_url)\n","time.sleep(5)\n","\n","# æ¨¡æ‹Ÿæ»šåŠ¨åŠ è½½æ›´å¤šè¯é¢˜å¡ç‰‡\n","for _ in range(10):\n","    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n","    time.sleep(2)\n","\n","# è§£æé¡µé¢\n","soup = BeautifulSoup(driver.page_source, \"html.parser\")\n","topic_cards = soup.find_all(\"a\", class_=\"TopicLink\")\n","\n","data = []\n","\n","for topic in topic_cards:\n","    try:\n","        topic_name = topic.get_text(strip=True)\n","        href = topic.get(\"href\")\n","        full_url = \"https://www.zhihu.com\" + href if href.startswith(\"/\") else href\n","\n","        # å‘ä¸Šå¯»æ‰¾å¡ç‰‡çˆ¶å…ƒç´ ï¼Œæå–ç®€ä»‹å’Œæµè§ˆæ•°\n","        parent_div = topic.find_parent(\"div\", class_=\"ContentItem-head\")\n","        description = \"\"\n","        views = \"\"\n","        discussions = \"\"\n","\n","        if parent_div:\n","            meta_div = parent_div.find_next(\"div\", class_=\"ContentItem-meta\")\n","            if meta_div:\n","                desc_div = meta_div.find(\"div\", class_=\"ztext\")\n","                status_links = meta_div.find_all(\"a\", class_=\"Search-statusLink\")\n","                if desc_div:\n","                    description = desc_div.get_text(strip=True)\n","                if status_links and len(status_links) >= 2:\n","                    views = status_links[0].get_text(strip=True)\n","                    discussions = status_links[1].get_text(strip=True)\n","\n","        data.append([topic_name, description, views, discussions, full_url])\n","        print(f\"æŠ“å–è¯é¢˜ï¼š{topic_name}\")\n","\n","    except Exception as e:\n","        print(\"å¿½ç•¥è¯é¢˜ï¼š\", e)\n","        continue\n","\n","driver.quit()\n","\n","# ä¿å­˜ä¸º CSV\n","df = pd.DataFrame(data, columns=[\"topic\", \"description\", \"views\", \"discussions\", \"url\"])\n","df.to_csv(\"zhihu_topics_2015.csv\", index=False, encoding=\"utf-8-sig\")\n","print(f\"å…±ä¿å­˜ {len(data)} ä¸ªè¯é¢˜åˆ° zhihu_topics_2015.csv\")\n","\n"],"metadata":{"id":"kNxXW-NdLeyY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#æ¯ä¸ªé¡µé¢çš„è¯é¢˜\n","\n","from selenium import webdriver\n","from selenium.webdriver.chrome.options import Options\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import time\n","\n","# è®¾ç½®å…³é”®è¯å’Œæœç´¢åœ°å€\n","search_keyword = \"2015\"\n","search_url = f\"https://www.zhihu.com/search?q={search_keyword}&type=content\"\n","\n","# é…ç½® Selenium æ— å¤´æµè§ˆå™¨\n","options = Options()\n","options.add_argument(\"--headless\")\n","options.add_argument(\"--no-sandbox\")\n","options.add_argument(\"--disable-dev-shm-usage\")\n","options.add_argument(\"start-maximized\")\n","options.add_argument(\"user-agent=Mozilla/5.0\")\n","\n","driver = webdriver.Chrome(options=options)\n","driver.get(search_url)\n","time.sleep(5)\n","\n","# æ»šåŠ¨åŠ è½½æ›´å¤šç»“æœ\n","for _ in range(15):\n","    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n","    time.sleep(2)\n","\n","# è§£æé¡µé¢\n","soup = BeautifulSoup(driver.page_source, \"html.parser\")\n","topic_cards = soup.find_all(\"a\", class_=\"TopicLink\")\n","\n","data = []\n","\n","for topic in topic_cards:\n","    try:\n","        # æ ‡é¢˜\n","        topic_name = topic.get_text(strip=True)\n","\n","        # é“¾æ¥\n","        href = topic.get(\"href\")\n","        full_url = \"https://www.zhihu.com\" + href if href.startswith(\"/\") else href\n","\n","        # æ‰¾ç®€ä»‹å’Œæ•°æ®\n","        parent_div = topic.find_parent(\"div\", class_=\"ContentItem-head\")\n","        description = \"\"\n","        views = \"\"\n","        discussions = \"\"\n","\n","        if parent_div:\n","            meta_div = parent_div.find_next(\"div\", class_=\"ContentItem-meta\")\n","            if meta_div:\n","                desc_div = meta_div.find(\"div\", class_=\"ztext\")\n","                status_links = meta_div.find_all(\"a\", class_=\"Search-statusLink\")\n","                if desc_div:\n","                    description = desc_div.get_text(strip=True)\n","                if status_links and len(status_links) >= 2:\n","                    views = status_links[0].get_text(strip=True)\n","                    discussions = status_links[1].get_text(strip=True)\n","\n","        data.append([topic_name, description, views, discussions, full_url])\n","        print(f\"âœ” æŠ“å–è¯é¢˜ï¼š{topic_name}\")\n","\n","    except Exception as e:\n","        print(\" å¿½ç•¥è¯é¢˜ï¼š\", e)\n","        continue\n","\n","driver.quit()\n","\n","# ä¿å­˜ä¸º CSV\n","df = pd.DataFrame(data, columns=[\"topic\", \"description\", \"views\", \"discussions\", \"url\"])\n","df.to_csv(\"zhihu_topics_20151.csv\", index=False, encoding=\"utf-8-sig\")\n","print(f\"æŠ“å–å®Œæˆï¼Œå…±ä¿å­˜ {len(data)} ä¸ªè¯é¢˜åˆ° zhihu_topics_2015.csv\")\n"],"metadata":{"id":"7mztScv0OQSE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#zhihu ç»¼åˆ 2015\n","\n","\n","from selenium import webdriver\n","from selenium.webdriver.chrome.options import Options\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import time\n","from datetime import datetime\n","\n","# è®¾ç½®å…³é”®è¯å’Œæœç´¢ç±»å‹ä¸ºç»¼åˆå†…å®¹\n","search_keyword = \"2015\"\n","search_url = f\"https://www.zhihu.com/search?q={search_keyword}&type=content\"\n","\n","# é…ç½® Selenium æµè§ˆå™¨\n","options = Options()\n","options.add_argument(\"--headless\")\n","options.add_argument(\"--no-sandbox\")\n","options.add_argument(\"--disable-dev-shm-usage\")\n","driver = webdriver.Chrome(options=options)\n","driver.get(search_url)\n","time.sleep(5)\n","\n","# æ¨¡æ‹Ÿä¸‹æ»‘åŠ è½½æ›´å¤šå†…å®¹\n","for _ in range(15):\n","    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n","    time.sleep(2)\n","\n","# è§£æé¡µé¢\n","soup = BeautifulSoup(driver.page_source, \"html.parser\")\n","cards = soup.find_all(\"div\", class_=\"SearchResult-Card\")\n","\n","data = []\n","\n","for card in cards:\n","    try:\n","        # é“¾æ¥\n","        link_tag = card.find(\"a\", href=True)\n","        if not link_tag:\n","            continue\n","        href = link_tag[\"href\"]\n","        url = \"https://www.zhihu.com\" + href if href.startswith(\"/question\") else href\n","\n","        # æ ‡é¢˜\n","        title = link_tag.get_text(strip=True)\n","\n","        # æ‘˜è¦\n","        summary_tag = card.find(\"div\", class_=\"RichContent-inner\")\n","        summary = summary_tag.get_text(strip=True) if summary_tag else \"\"\n","\n","        # ä½œè€…\n","        author_tag = card.find(\"div\", class_=\"AuthorInfo-head\")\n","        author = author_tag.get_text(strip=True) if author_tag else \"åŒ¿å\"\n","\n","        # æ—¶é—´ï¼ˆå°è¯•æå–ï¼‰\n","        time_tag = card.find(\"time\")\n","        date_str = time_tag[\"datetime\"][:10] if time_tag and \"datetime\" in time_tag.attrs else \"\"\n","        try:\n","            date = datetime.strptime(date_str, \"%Y-%m-%d\") if date_str else None\n","        except:\n","            date = None\n","\n","        # è‹¥æœªæå–åˆ°æ—¶é—´ï¼Œä½†å…³é”®è¯ä¸­æ˜ç¡®åŒ…å«â€œ2015â€ï¼Œä¹Ÿå¯ä¿ç•™\n","        if date is None and \"2015\" in summary:\n","            date = datetime(2015, 1, 1)\n","\n","        if date and datetime(2015, 1, 1) <= date <= datetime(2025, 12, 31):\n","            data.append([title, author, date.strftime(\"%Y-%m-%d\"), summary, url])\n","            print(\"âœ” æŠ“å–ï¼š\", title)\n","\n","    except Exception as e:\n","        print(\"å¿½ç•¥å†…å®¹ï¼š\", e)\n","        continue\n","\n","driver.quit()\n","\n","# ä¿å­˜ä¸º CSV æ–‡ä»¶\n","df = pd.DataFrame(data, columns=[\"title\", \"author\", \"date\", \"summary\", \"link\"])\n","df.to_csv(\"zhihu_mixed_2015_2025.csv\", index=False, encoding=\"utf-8-sig\")\n","print(f\"å®Œæˆï¼Œå…±ä¿å­˜ {len(data)} æ¡å†…å®¹åˆ° zhihu_mixed_2015_2025.csv\")\n"],"metadata":{"id":"0wIP3xVVMccB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"exMTRTmuXCAR"}},{"cell_type":"markdown","source":["#å½­åšæ–°é—»"],"metadata":{"id":"QZNuvSTbTJzV"}},{"cell_type":"markdown","source":["#4) Weibo"],"metadata":{"id":"DYC3D_T0OjGw"}},{"cell_type":"code","source":[],"metadata":{"id":"AP4V3S_vPJQH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#5)Douban"],"metadata":{"id":"KiyjFr_BPJxA"}},{"cell_type":"code","source":[],"metadata":{"id":"ouWCMBvTPLTg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#6)blibli - vidÃ©o"],"metadata":{"id":"YfrTzI6OPMQI"}},{"cell_type":"code","source":[],"metadata":{"id":"XQHvgxxQPOfl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"5n_e1FkbP66v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"GA5ibPfQTHoJ"}},{"cell_type":"markdown","source":["#7baidu ç™¾åº¦æ–°é—» ï¼š https://www.baidu.com/s?tn=news&word=2015&pn=100\n","\n","\n","\n","#æŸ¥è¯¢ï¼š https://www.google.com/advanced_search?q=site:thepaper.cn+2015&client=firefox-b-d&sca_esv=4d1e52ecd0f51357&sxsrf=AE3TifOp3VsAjjic0H6D16Q26gmvMKT8dQ:1753550785198&tbas=0&biw=1232&bih=728&dpr=2\n"],"metadata":{"id":"yQfNst62wozZ"}},{"cell_type":"markdown","source":["# **Corpus en vietnamien**"],"metadata":{"id":"s894kKgpVOz0"}},{"cell_type":"markdown","source":["#1)https://kenh14.vn\n","\n","\n"],"metadata":{"id":"KAeS7LtzVpl0"}},{"cell_type":"code","source":["! pip install requests beautifulsoup4 pandas\n"],"metadata":{"id":"Wz8kum1kY5Zh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import csv\n","\n","# ç›®æ ‡ç½‘å€\n","url = 'https://kenh14.vn/chum-anh-can-canh-rapper-binh-gold-thoi-diem-bi-csgt-truy-bat-tren-cao-toc-215250724113851073.chn'\n","\n","headers = {\n","    'User-Agent': 'Mozilla/5.0'\n","}\n","response = requests.get(url, headers=headers)\n","soup = BeautifulSoup(response.content, 'html.parser')\n","\n","# 1. æ ‡é¢˜\n","title = soup.find('h1', class_='kbwc-title')\n","title_text = title.get_text(strip=True) if title else 'N/A'\n","\n","# 2. æ—¥æœŸ\n","date = soup.find('span', class_='kbwcm-time')\n","date_text = date.get_text(strip=True) if date else 'N/A'\n","\n","# 3. ä½œè€…\n","author = soup.find('span', class_='kbwcm-author')\n","author_text = author.get_text(strip=True).rstrip(',') if author else 'N/A'\n","\n","# 4. æ­£æ–‡å†…å®¹ï¼ˆåªå– <div class=\"detail-content\"> ä¸‹æ‰€æœ‰æ®µè½æ–‡å­—ï¼‰\n","content_div = soup.find('div', class_='detail-content')\n","if content_div:\n","    paragraphs = content_div.find_all('p')\n","    content_text = '\\n'.join(p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True))\n","else:\n","    content_text = 'N/A'\n","\n","# 5. æ¥æº\n","source_text = url  # åŸç½‘é¡µé“¾æ¥\n","\n","# å†™å…¥ CSV\n","with open('kenh2025_article1.csv', 'w', encoding='utf-8-sig', newline='') as f:\n","    writer = csv.DictWriter(f, fieldnames=['author', 'title', 'date', 'content', 'source'])\n","    writer.writeheader()\n","    writer.writerow({\n","        'author': author_text,\n","        'title': title_text,\n","        'date': date_text,\n","        'content': content_text,\n","        'source': source_text\n","    })\n","\n","print(\" å·²ä¿å­˜ä¸º kenh14_article.csv\")\n"],"metadata":{"id":"LH1dlMXRWluq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import csv\n","\n","# -------------------------------------------------------\n","#  Extraction pour l'article que tu as indiquÃ©\n","# -------------------------------------------------------\n","\n","url = \"https://kenh14.vn/hoc-duong/ky-thi-thpt-quoc-gia-2015-lich-thi-cua-dh-quoc-gia-ha-noi-20150314080244768.chn\"\n","headers = {'User-Agent': 'Mozilla/5.0'}\n","\n","response = requests.get(url, headers=headers)\n","response.encoding = 'utf-8'\n","soup = BeautifulSoup(response.content, \"html.parser\")\n","\n","# 1. Auteur\n","author_tag = soup.find('span', class_='kbwcm-author')\n","author_text = author_tag.get_text(strip=True).rstrip(',') if author_tag else ''\n","\n","# 2. Titre\n","title_tag = soup.find('h1', class_='kbwc-title')\n","title_text = title_tag.get_text(strip=True) if title_tag else ''\n","\n","# 3. Date\n","date_tag = soup.find('span', class_='kbwcm-time')\n","date_text = date_tag.get_text(strip=True) if date_tag else ''\n","\n","# 4. Contenu principal\n","# On cible <div class=\"klwâ€‘newâ€‘content\"> puis on rÃ©cupÃ¨re\n","# le chapeau sapo (optionnel) + tous les paragraphes dans <div class=\"knc-content\">\n","content_list = []\n","sapo = soup.find('h2', class_='knc-sapo')\n","if sapo:\n","    sapo_text = sapo.get_text(strip=True)\n","    if sapo_text:\n","        content_list.append(sapo_text)\n","\n","main_div = soup.find('div', class_='knc-content')\n","if main_div:\n","    for p in main_div.find_all('p'):\n","        text = p.get_text(strip=True)\n","        if text:\n","            content_list.append(text)\n","\n","content_text = \"\\n\\n\".join(content_list)\n","\n","# 5. URL de la page\n","page_url = url\n","\n","# 6. Ecrire dans un CSV\n","with open('kenh2015_4.csv', 'w', encoding='utf-8-sig', newline='') as f:\n","    writer = csv.DictWriter(f, fieldnames=['author', 'title', 'date', 'content', 'url'])\n","    writer.writeheader()\n","    writer.writerow({\n","        'author': author_text,\n","        'title': title_text,\n","        'date': date_text,\n","        'content': content_text,\n","        'url': page_url\n","    })\n","\n","print(\" Fichier kenh2015_.csv crÃ©Ã© avec succÃ¨s\")\n"],"metadata":{"id":"biNEMk63Mihw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#2016\n","\n","import requests\n","from bs4 import BeautifulSoup\n","import csv\n","\n","# -------------------------------------------------------\n","#  Extraction pour l'article que tu as indiquÃ©\n","# -------------------------------------------------------\n","\n","url = \"https://kenh14.vn/top-3-hoa-hau-viet-nam-2022-nguoi-thang-giai-quoc-te-nguoi-hoc-len-thac-si-215241122144704936.chn\"\n","headers = {'User-Agent': 'Mozilla/5.0'}\n","\n","response = requests.get(url, headers=headers)\n","response.encoding = 'utf-8'\n","soup = BeautifulSoup(response.content, \"html.parser\")\n","\n","# 1. Auteur\n","author_tag = soup.find('span', class_='kbwcm-author')\n","author_text = author_tag.get_text(strip=True).rstrip(',') if author_tag else ''\n","\n","# 2. Titre\n","title_tag = soup.find('h1', class_='kbwc-title')\n","title_text = title_tag.get_text(strip=True) if title_tag else ''\n","\n","# 3. Date\n","date_tag = soup.find('span', class_='kbwcm-time')\n","date_text = date_tag.get_text(strip=True) if date_tag else ''\n","\n","# 4. Contenu principal\n","# On cible <div class=\"klwâ€‘newâ€‘content\"> puis on rÃ©cupÃ¨re\n","# le chapeau sapo (optionnel) + tous les paragraphes dans <div class=\"knc-content\">\n","content_list = []\n","sapo = soup.find('h2', class_='knc-sapo')\n","if sapo:\n","    sapo_text = sapo.get_text(strip=True)\n","    if sapo_text:\n","        content_list.append(sapo_text)\n","\n","main_div = soup.find('div', class_='knc-content')\n","if main_div:\n","    for p in main_div.find_all('p'):\n","        text = p.get_text(strip=True)\n","        if text:\n","            content_list.append(text)\n","\n","content_text = \"\\n\\n\".join(content_list)\n","\n","# 5. URL de la page\n","page_url = url\n","\n","# 6. Ecrire dans un CSV\n","with open('kenh2024_22.csv', 'w', encoding='utf-8-sig', newline='') as f:\n","    writer = csv.DictWriter(f, fieldnames=['author', 'title', 'date', 'content', 'url'])\n","    writer.writeheader()\n","    writer.writerow({\n","        'author': author_text,\n","        'title': title_text,\n","        'date': date_text,\n","        'content': content_text,\n","        'url': page_url\n","    })\n","\n","print(\" Fichier kenh2015_.csv crÃ©Ã© avec succÃ¨s\")\n"],"metadata":{"id":"nDG6Iog8NDTk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#ä¸‹è½½åŒ…\n","\n","\n","import zipfile\n","import os\n","\n","zip_path = \"/content/kenh_all_csv.zip\"\n","with zipfile.ZipFile(zip_path, 'w') as zipf:\n","    for file in os.listdir(\"/content\"):\n","        if file.endswith(\".csv\") and file.startswith(\"kenh2024_\"):\n","            zipf.write(os.path.join(\"/content\", file), arcname=file)"],"metadata":{"id":"c7hcNeMNn-W2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","files.download(\"/content/kenh_all_csv.zip\")\n"],"metadata":{"id":"EVD5gViMn9Hx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#2) https://cafebiz.vn\n"],"metadata":{"id":"0tv0EN_TWVOm"}},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","\n","# ç›®æ ‡ç½‘é¡µ\n","url = \"https://cafebiz.vn/quoc-hoi-se-bau-chu-tich-nuoc-vao-thang-10-2024-17624082621173561.chn\"\n","headers = {\"User-Agent\": \"Mozilla/5.0\"}\n","\n","# è¯·æ±‚ç½‘é¡µå†…å®¹\n","response = requests.get(url, headers=headers)\n","soup = BeautifulSoup(response.content, \"html.parser\")\n","\n","# 1. æ ‡é¢˜\n","title_tag = soup.find(\"h1\", class_=\"title\")\n","title = title_tag.get_text(strip=True) if title_tag else \"\"\n","\n","# 2. æ—¥æœŸ\n","date_tag = soup.find(\"span\", class_=\"time\")\n","date = date_tag.get_text(strip=True) if date_tag else \"\"\n","\n","# 3. ä½œè€…ï¼ˆä¼˜å…ˆå°è¯•ä½œè€…æ ï¼Œå†å°è¯•æ¥æºæ ï¼‰\n","author = \"\"\n","author_byline = soup.find(\"strong\", class_=\"detail-author\")\n","if author_byline and author_byline.get_text(strip=True):\n","    author = author_byline.get_text(strip=True).replace(\"Theo\", \"\").strip()\n","else:\n","    author_tag = soup.find(\"span\", class_=\"link-source-text-name\")\n","    if author_tag:\n","        author = author_tag.get_text(strip=True)\n","\n","# 4. æ­£æ–‡å†…å®¹ï¼ˆåªæå–<p>å’Œ<blockquote>ä¸­çš„çº¯æ–‡æœ¬ï¼‰\n","content_div = soup.find(\"div\", class_=\"detail-content\")\n","content = \"\"\n","if content_div:\n","    for tag in content_div.find_all([\"p\", \"blockquote\"]):\n","        text = tag.get_text(strip=True)\n","        if text:\n","            content += text + \"\\n\"\n","\n","# 5. æ¥æºï¼ˆå½“å‰URLï¼‰\n","source = url\n","\n","# 6. æ„å»ºDataFrameå¹¶ä¿å­˜ä¸ºCSV\n","data = {\n","    \"author\": [author],\n","    \"title\": [title],\n","    \"date\": [date],\n","    \"content\": [content.strip()],\n","    \"source\": [source]\n","}\n","\n","df = pd.DataFrame(data)\n","df.to_csv(\"cafebiz2024_25.csv\", index=False, encoding=\"utf-8-sig\")\n","print(\"æŠ“å–æˆåŠŸï¼Œå·²ä¿å­˜ä¸º cafebiz2021_1.csv\")\n"],"metadata":{"id":"eeXLUn-HYVkT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#ä¸‹è½½åŒ…\n","\n","\n","import zipfile\n","import os\n","\n","zip_path = \"/content/cafebiz_all_csv.zip\"\n","with zipfile.ZipFile(zip_path, 'w') as zipf:\n","    for file in os.listdir(\"/content\"):\n","        if file.endswith(\".csv\") and file.startswith(\"cafebiz2024_\"):\n","            zipf.write(os.path.join(\"/content\", file), arcname=file)"],"metadata":{"id":"8bFZwjw49Rys"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","files.download(\"/content/cafebiz_all_csv.zip\")\n"],"metadata":{"id":"vQVmj6Is9U9Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#3) https://genk.vn\n","\n","\n","#æŸ¥è¯¢https://www.google.com/advanced_search?q=site:thepaper.cn+2015&client=firefox-b-d&sca_esv=4d1e52ecd0f51357&sxsrf=AE3TifOp3VsAjjic0H6D16Q26gmvMKT8dQ:1753550785198&tbas=0&biw=1232&bih=728&dpr=2\n"],"metadata":{"id":"dRFAAueVWXMU"}},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","\n","url = \"https://genk.vn/ro-ri-ve-khung-long-rtx-5090-32gb-vram-gddr7-cuc-khung-hieu-nang-vuot-troi-nhung-ngon-dien-kinh-hoang-20250107002116059.chn\"\n","headers = {\"User-Agent\": \"Mozilla/5.0\"}\n","response = requests.get(url, headers=headers)\n","soup = BeautifulSoup(response.content, \"html.parser\")\n","\n","# æ ‡é¢˜\n","title_tag = soup.find(\"h1\")\n","title = title_tag.get_text(strip=True) if title_tag else \"\"\n","\n","# æ—¥æœŸ\n","date_tag = soup.find(\"span\", class_=\"kbwcm-time\")\n","date = date_tag.get(\"title\", \"\").strip() if date_tag else \"\"\n","\n","# ä½œè€…\n","author_tag = soup.find(\"span\", class_=\"kbwcm-author\")\n","author = author_tag.get_text(strip=True).replace(\",\", \"\").strip() if author_tag else \"\"\n","\n","# æ­£æ–‡å†…å®¹\n","content = \"\"\n","# ç¬¬ä¸€æ®µä»‹ç»ï¼š<h2 class=\"knc-sapo\">\n","sapo = soup.find(\"h2\", class_=\"knc-sapo\")\n","if sapo:\n","    content += sapo.get_text(strip=True) + \"\\n\"\n","\n","# æ­£æ–‡æ®µè½ <div id=\"ContentDetail\">\n","content_div = soup.find(\"div\", id=\"ContentDetail\")\n","if content_div:\n","    for tag in content_div.find_all(\"p\"):\n","        text = tag.get_text(strip=True)\n","        if text:\n","            content += text + \"\\n\"\n","\n","# æ¥æº\n","source = url\n","\n","# æ„å»º DataFrame\n","data = {\n","    \"author\": [author],\n","    \"title\": [title],\n","    \"date\": [date],\n","    \"content\": [content.strip()],\n","    \"source\": [source]\n","}\n","\n","# å¯¼å‡ºä¸º CSV\n","df = pd.DataFrame(data)\n","df.to_csv(\"genk2025_23.csv\", index=False, encoding=\"utf-8-sig\")\n","print(\"æŠ“å–æˆåŠŸï¼Œå·²ä¿å­˜ä¸º genk_article.csv\")\n"],"metadata":{"id":"yfRT1RJtaZAG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#ä¸‹è½½åŒ…\n","\n","\n","import zipfile\n","import os\n","\n","zip_path = \"/content/genk_all_csv.zip\"\n","with zipfile.ZipFile(zip_path, 'w') as zipf:\n","    for file in os.listdir(\"/content\"):\n","        if file.endswith(\".csv\") and file.startswith(\"genk2025_\"):\n","            zipf.write(os.path.join(\"/content\", file), arcname=file)"],"metadata":{"id":"M_zMuENDpE0V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","files.download(\"/content/genk_all_csv.zip\")\n"],"metadata":{"id":"UspHqsREpHOO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#âŒ4) https://baomoi.com\n","\n","\n","\n","#æŸ¥è¯¢https://www.google.com/advanced_search?q=site:thepaper.cn+2015&client=firefox-b-d&sca_esv=4d1e52ecd0f51357&sxsrf=AE3TifOp3VsAjjic0H6D16Q26gmvMKT8dQ:1753550785198&tbas=0&biw=1232&bih=728&dpr=2\n","\n"],"metadata":{"id":"P4Ley8ZXWaWY"}},{"cell_type":"code","source":["#2015\n","\n","import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","\n","# è¦æŠ“å–çš„ç½‘å€\n","url = \"https://vtcnews.vn/ky-thi-thpt-quoc-gia-2015-cham-bai-thi-trac-nghiem-the-nao-ar189669.html\"\n","headers = {\"User-Agent\": \"Mozilla/5.0\"}\n","response = requests.get(url, headers=headers)\n","soup = BeautifulSoup(response.content, \"html.parser\")\n","\n","# æ ‡é¢˜ï¼ˆæ³¨æ„æ˜¯ <h2 class=\"text-title\">ï¼‰\n","title_tag = soup.find(\"h2\", class_=\"text-title\")\n","title = title_tag.get_text(strip=True) if title_tag else \"\"\n","\n","# ä½œè€…ï¼ˆæ³¨æ„æ˜¯ <strong> æ ‡ç­¾å†…ï¼Œæœ«å°¾å¯èƒ½é‡å¤ä¸€æ¬¡ï¼‰\n","author_tag = soup.find(\"strong\")\n","author = author_tag.get_text(strip=True) if author_tag else \"\"\n","\n","# æ—¥æœŸï¼ˆ<span class=\"time\">ï¼‰\n","date_tag = soup.find(\"span\", class_=\"time\")\n","date = date_tag.get_text(strip=True) if date_tag else \"\"\n","\n","# æ­£æ–‡å†…å®¹ï¼ˆåœ¨ <div class=\"detail-content afcbc-body\" data-role=\"content\">ï¼‰\n","content = \"\"\n","content_div = soup.find(\"div\", class_=\"detail-content\")\n","if content_div:\n","    paragraphs = content_div.find_all(\"p\", class_=\"body-text\")\n","    for p in paragraphs:\n","        text = p.get_text(strip=True)\n","        if text:\n","            content += text + \"\\n\"\n","\n","# æ„å»º DataFrame\n","data = {\n","    \"author\": [author],\n","    \"title\": [title],\n","    \"date\": [date],\n","    \"content\": [content.strip()],\n","    \"source\": [url]\n","}\n","\n","# å¯¼å‡ºä¸º CSV\n","df = pd.DataFrame(data)\n","df.to_csv(\"baomoi2015_2.csv\", index=False, encoding=\"utf-8-sig\")\n","print(\"æŠ“å–æˆåŠŸï¼Œå·²ä¿å­˜ä¸º nguoiduatin_article.csv\")\n"],"metadata":{"id":"95ievOW956aG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#VTCNews\n","\n"],"metadata":{"id":"-RWnVj3A622H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#2025\n","\n","import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","\n","url = \"https://www.nguoiduatin.vn/dap-an-de-thi-mon-tieng-anh-vao-lop-10-nam-2015-tai-ha-noi-204193589.htm\"\n","headers = {\"User-Agent\": \"Mozilla/5.0\"}\n","response = requests.get(url, headers=headers)\n","soup = BeautifulSoup(response.content, \"html.parser\")\n","\n","# æ ‡é¢˜\n","title_tag = soup.find(\"h1\", class_=\"detail-title\")\n","title = title_tag.get_text(strip=True) if title_tag else \"\"\n","\n","# ä½œè€…\n","author_tag = soup.find(\"p\", class_=\"name\")\n","author = author_tag.get_text(strip=True) if author_tag else \"\"\n","\n","# æ—¥æœŸ\n","date_tag = soup.find(\"div\", attrs={\"data-role\": \"publishdate\"})\n","date = date_tag.get_text(strip=True) if date_tag else \"\"\n","\n","# æ­£æ–‡å†…å®¹\n","content_div = soup.find(\"div\", class_=\"detail-content\")\n","content = \"\"\n","\n","if content_div:\n","    paragraphs = content_div.find_all(\"p\")\n","    for p in paragraphs:\n","        text = p.get_text(strip=True)\n","        if text:\n","            content += text + \"\\n\"\n","\n","# æ„å»º DataFrame\n","data = {\n","    \"author\": [author],\n","    \"title\": [title],\n","    \"date\": [date],\n","    \"content\": [content.strip()],\n","    \"source\": [url]\n","}\n","\n","df = pd.DataFrame(data)\n","df.to_csv(\"baomoi2015_2.csv\", index=False, encoding=\"utf-8-sig\")\n","print(\"æŠ“å–æˆåŠŸï¼Œå·²ä¿å­˜ä¸º nld_article_20250807.csv\")\n"],"metadata":{"id":"CdX74o2v19Vx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#ä¸‹è½½åŒ…\n","\n","\n","import zipfile\n","import os\n","\n","zip_path = \"/content/genk_all_csv.zip\"\n","with zipfile.ZipFile(zip_path, 'w') as zipf:\n","    for file in os.listdir(\"/content\"):\n","        if file.endswith(\".csv\") and file.startswith(\"genk2025_\"):\n","            zipf.write(os.path.join(\"/content\", file), arcname=file)"],"metadata":{"id":"8i11S1HP10uJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","files.download(\"/content/genk_all_csv.zip\")\n"],"metadata":{"id":"bF0V65v_119e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#âŒ 5) https://vnexpress.net\n","\n","#æŸ¥è¯¢https://www.google.com/advanced_search?q=site:thepaper.cn+2015&client=firefox-b-d&sca_esv=4d1e52ecd0f51357&sxsrf=AE3TifOp3VsAjjic0H6D16Q26gmvMKT8dQ:1753550785198&tbas=0&biw=1232&bih=728&dpr=2\n","\n","\n","\n"],"metadata":{"id":"cyz1rfqmWcsy"}},{"cell_type":"code","source":["#anti-scrapping\n","\n","import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","\n","# ç½‘å€\n","url = \"https://vnexpress.net/khoanh-khac-buon-cua-messi-thang-giai-anh-bao-chi-the-gioi-2014-3147342.html\"\n","headers = {\"User-Agent\": \"Mozilla/5.0\"}\n","\n","# å‘é€è¯·æ±‚\n","response = requests.get(url, headers=headers)\n","soup = BeautifulSoup(response.content, \"html.parser\")\n","\n","# æŠ“å–æ ‡é¢˜\n","title_tag = soup.find(\"h1\", class_=\"title-detail\")\n","title = title_tag.get_text(strip=True) if title_tag else \"\"\n","\n","# æŠ“å–ä½œè€…\n","author_tag = soup.find(\"strong\")\n","author = author_tag.get_text(strip=True) if author_tag else \"\"\n","\n","# æŠ“å–æ—¶é—´\n","date_tag = soup.find(\"span\", class_=\"date\")\n","date = date_tag.get_text(strip=True) if date_tag else \"\"\n","\n","# æŠ“å–æ­£æ–‡å†…å®¹ï¼ˆåŒ…æ‹¬æ‘˜è¦ + æ­£æ–‡æ®µè½ï¼‰\n","content = \"\"\n","\n","# æ‘˜è¦æ®µè½\n","desc_tag = soup.find(\"p\", class_=\"description\")\n","if desc_tag:\n","    content += desc_tag.get_text(strip=True) + \"\\n\"\n","\n","# ä¸»ä½“æ®µè½\n","paragraphs = soup.find_all(\"p\", class_=\"Normal\")\n","for p in paragraphs:\n","    text = p.get_text(strip=True)\n","    if text:\n","        content += text + \"\\n\"\n","\n","# æ„å»º DataFrame\n","data = {\n","    \"author\": [author],\n","    \"title\": [title],\n","    \"date\": [date],\n","    \"content\": [content.strip()],\n","    \"source\": [url]\n","}\n","\n","df = pd.DataFrame(data)\n","\n","# ä¿å­˜ä¸º CSV æ–‡ä»¶\n","df.to_csv(\"vnexpress_messi_2014.csv\", index=False, encoding=\"utf-8-sig\")\n","print(\"æŠ“å–æˆåŠŸï¼Œå·²ä¿å­˜ä¸º vnexpress_messi_2014.csv\")\n"],"metadata":{"id":"R5uCOH-I7w-9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# å®‰è£… Chromium å’Œ ChromeDriver\n","!apt-get update > /dev/null\n","!apt-get install -y chromium chromium-driver > /dev/null\n","\n","# å®‰è£… Selenium\n","!pip install -q selenium\n"],"metadata":{"id":"I0uk_GeMCt3Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from selenium import webdriver\n","from selenium.webdriver.chrome.service import Service\n","from selenium.webdriver.chrome.options import Options\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import time\n","\n","# é…ç½® Chrome é€‰é¡¹ï¼ˆHeadless + Colab å…¼å®¹ï¼‰\n","chrome_options = Options()\n","chrome_options.add_argument(\"--headless\")\n","chrome_options.add_argument(\"--no-sandbox\")\n","chrome_options.add_argument(\"--disable-dev-shm-usage\")\n","chrome_options.binary_location = \"/usr/bin/chromium\"\n","\n","# å¯åŠ¨æµè§ˆå™¨\n","driver = webdriver.Chrome(service=Service(\"/usr/lib/chromium/chromedriver\"), options=chrome_options)\n","\n","# æŠ“å–ç½‘é¡µ\n","url = \"https://vnexpress.net/khoanh-khac-buon-cua-messi-thang-giai-anh-bao-chi-the-gioi-2014-3147342.html\"\n","driver.get(url)\n","time.sleep(3)  # ç­‰å¾…é¡µé¢åŠ è½½å®Œæ¯•\n","\n","# è§£æ HTML\n","soup = BeautifulSoup(driver.page_source, \"html.parser\")\n","driver.quit()\n","\n","# æå–ä¿¡æ¯\n","title_tag = soup.find(\"h1\", class_=\"title-detail\")\n","title = title_tag.get_text(strip=True) if title_tag else \"\"\n","\n","author_tag = soup.find(\"strong\")\n","author = author_tag.get_text(strip=True) if author_tag else \"\"\n","\n","date_tag = soup.find(\"span\", class_=\"date\")\n","date = date_tag.get_text(strip=True) if date_tag else \"\"\n","\n","# æŠ“å–æ­£æ–‡å†…å®¹ï¼ˆåŒ…æ‹¬æ‘˜è¦ + æ®µè½ï¼‰\n","content = \"\"\n","desc_tag = soup.find(\"p\", class_=\"description\")\n","if desc_tag:\n","    content += desc_tag.get_text(strip=True) + \"\\n\"\n","\n","for p in soup.find_all(\"p\", class_=\"Normal\"):\n","    text = p.get_text(strip=True)\n","    if text:\n","        content += text + \"\\n\"\n","\n","# æ„å»º DataFrame\n","df = pd.DataFrame([{\n","    \"author\": author,\n","    \"title\": title,\n","    \"date\": date,\n","    \"content\": content.strip(),\n","    \"source\": url\n","}])\n","\n","# ä¿å­˜ä¸º CSV\n","df.to_csv(\"vnexpress_messi_colab.csv\", index=False, encoding=\"utf-8-sig\")\n","print(\"æŠ“å–æˆåŠŸï¼æ–‡ä»¶åï¼švnexpress_messi_colab.csv\")\n"],"metadata":{"id":"g_bNAHzSCnRy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#ä¸‹è½½åŒ…\n","\n","\n","import zipfile\n","import os\n","\n","zip_path = \"/content/vnexpress_all_csv.zip\"\n","with zipfile.ZipFile(zip_path, 'w') as zipf:\n","    for file in os.listdir(\"/content\"):\n","        if file.endswith(\".csv\") and file.startswith(\"vnexpress2015_\"):\n","            zipf.write(os.path.join(\"/content\", file), arcname=file)"],"metadata":{"id":"OjKCsbb814Hd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","files.download(\"/content/genk_all_csv.zip\")\n"],"metadata":{"id":"AFdjh0Pm12oy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#6) https://webtretho.com (forum)\n","\n","\n","#æŸ¥è¯¢https://www.google.com/advanced_search?q=site:thepaper.cn+2015&client=firefox-b-d&sca_esv=4d1e52ecd0f51357&sxsrf=AE3TifOp3VsAjjic0H6D16Q26gmvMKT8dQ:1753550785198&tbas=0&biw=1232&bih=728&dpr=2\n","\n","\n","\n"],"metadata":{"id":"bh29fj5uWg5Z"}},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","\n","# ç›®æ ‡ç½‘å€\n","url = \"https://www.webtretho.com/f/tam-su-chuyen-cong-viec-cong-so/4-2015-tap-doan-nam-long-cong-bo-mo-ban-dot-cuoi-3-lo-dep-nhat-c5-c6-va-c7-nhan-nha-nam-2015-2036813\"\n","headers = {\"User-Agent\": \"Mozilla/5.0\"}\n","response = requests.get(url, headers=headers)\n","soup = BeautifulSoup(response.content, \"html.parser\")\n","\n","# --------------------------\n","# æå–æ ‡é¢˜\n","title_tag = soup.find(\"h1\", class_=\"text-wrap tw-font-bold text-primary tw-mt-2.5 tw-mb-1 tw-text-3xl\")\n","title = title_tag.get_text(strip=True) if title_tag else \"\"\n","\n","# æå–ä½œè€…\n","author_tag = soup.find(\"a\", class_=\"tw-font-bold text-main tw-text-xs\")\n","author = author_tag.get_text(strip=True) if author_tag else \"\"\n","\n","# æå–æ—¥æœŸï¼ˆæ³¨ï¼šè¿™é‡Œæ˜¯â€œå‡ ä¸ªæœˆå‰â€çš„å½¢å¼ï¼‰\n","date_tag = soup.find(\"div\", class_=\"tw-text-xs text-gray-v2\")\n","date = date_tag.get_text(strip=True) if date_tag else \"\"\n","\n","# æå–æ­£æ–‡å†…å®¹ï¼š<div id=\"post-content\">\n","content = \"\"\n","content_div = soup.find(\"div\", id=\"post-content\")\n","if content_div:\n","    for p in content_div.find_all(\"p\", class_=\"editor-text-justify\"):\n","        text = p.get_text(strip=True)\n","        if text:\n","            content += text + \"\\n\"\n","\n","# æ„å»º dataframe\n","data = {\n","    \"author\": [author],\n","    \"title\": [title],\n","    \"date\": [date],\n","    \"content\": [content.strip()],\n","    \"source\": [url]\n","}\n","\n","df = pd.DataFrame(data)\n","\n","# ä¿å­˜ä¸º CSV\n","df.to_csv(\"webtretho2015_2.csv\", index=False, encoding=\"utf-8-sig\")\n","print(\"æŠ“å–æˆåŠŸï¼Œå·²ä¿å­˜ä¸º webtretho_luat_2015.csv\")\n"],"metadata":{"id":"PzQp2va5FOt9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","\n","# ç›®æ ‡ç½‘å€\n","url = \"https://www.webtretho.com/f/hoc-tap-va-nghien-cuu/chia-se-phan-mem-dong-goi-installshield-2015\"\n","headers = {\"User-Agent\": \"Mozilla/5.0\"}\n","response = requests.get(url, headers=headers)\n","soup = BeautifulSoup(response.content, \"html.parser\")\n","\n","# --------------------------\n","# æå–æ ‡é¢˜\n","title_tag = soup.find(\"h1\", class_=\"text-wrap tw-font-bold text-primary tw-mt-2.5 tw-mb-1 tw-text-3xl\")\n","title = title_tag.get_text(strip=True) if title_tag else \"\"\n","\n","# æå–ä½œè€…\n","author_tag = soup.find(\"a\", class_=\"tw-font-bold text-main tw-text-xs\")\n","author = author_tag.get_text(strip=True) if author_tag else \"\"\n","\n","# æå–æ—¥æœŸ\n","date_tag = soup.find(\"div\", class_=\"tw-text-xs text-gray-v2\")\n","date = date_tag.get_text(strip=True) if date_tag else \"\"\n","\n","# æå–æ­£æ–‡å†…å®¹ï¼ˆæ³¨æ„ï¼šè¿™æ®µæ–‡å­—ä¸å®Œå…¨åœ¨ <p> ä¸­ï¼‰\n","content = \"\"\n","content_div = soup.find(\"div\", id=\"post-content\")\n","if content_div:\n","    # æå–æ‰€æœ‰æ–‡å­—èŠ‚ç‚¹ï¼ˆä¸ç®¡ä»€ä¹ˆæ ‡ç­¾ï¼‰\n","    content = content_div.get_text(separator=\"\\n\", strip=True)\n","\n","# æ„å»º dataframe\n","data = {\n","    \"author\": [author],\n","    \"title\": [title],\n","    \"date\": [date],\n","    \"content\": [content],\n","    \"source\": [url]\n","}\n","\n","df = pd.DataFrame(data)\n","\n","# ä¿å­˜ä¸º CSV\n","df.to_csv(\"webtretho2015_5.csv\", index=False, encoding=\"utf-8-sig\")\n","print(\"æŠ“å–æˆåŠŸï¼Œå·²ä¿å­˜ä¸º webtretho2015_2.csv\")\n"],"metadata":{"id":"eJGVDnZ3HHRC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Forum\n","\n","import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","\n","# æ ‡ç­¾é¡µ URL\n","url = \"https://www.webtretho.com/tags/rong-bien\"\n","headers = {\"User-Agent\": \"Mozilla/5.0\"}\n","response = requests.get(url, headers=headers)\n","soup = BeautifulSoup(response.content, \"html.parser\")\n","\n","# åˆå§‹åŒ–æ•°æ®åˆ—è¡¨\n","posts = []\n","\n","# éå†æ‰€æœ‰å¸–å­å®¹å™¨\n","# æ¯ä¸ªå¸–å­æ˜¯ <div role=\"article\">...</div>\n","for article in soup.find_all(\"div\", attrs={\"role\": \"article\"}):\n","    # æ ‡é¢˜\n","    title_tag = article.find(\"h4\")\n","    title = title_tag.get_text(strip=True) if title_tag else \"\"\n","\n","    # ä½œè€…\n","    author_tag = article.find(\"a\", class_=\"tw-font-bold text-main tw-text-xs\")\n","    author = author_tag.get_text(strip=True) if author_tag else \"\"\n","\n","    # æ—¥æœŸ\n","    date_tag = article.find(\"div\", class_=\"tw-text-xs text-gray-blue tw-mt-1.5\")\n","    date = date_tag.get_text(strip=True) if date_tag else \"\"\n","\n","    # å†…å®¹ï¼ˆæ­£æ–‡æ‘˜è¦ï¼‰\n","    content_tag = article.find(\"div\", class_=\"tw-leading-5 tw-text-sm text-black tw-whitespace-normal tw-break-words w-100 max-l-2\")\n","    content = content_tag.get_text(separator=\"\\n\", strip=True) if content_tag else \"\"\n","\n","    # é“¾æ¥\n","    link_tag = title_tag.find_parent(\"a\") if title_tag else None\n","    href = \"https://www.webtretho.com\" + link_tag[\"href\"] if link_tag and link_tag.has_attr(\"href\") else url\n","\n","    # æ·»åŠ ä¸€è¡Œæ•°æ®\n","    posts.append({\n","        \"title\": title,\n","        \"author\": author,\n","        \"date\": date,\n","        \"content\": content,\n","        \"link\": href\n","    })\n","\n","# ä¿å­˜ä¸º CSV\n","df = pd.DataFrame(posts)\n","df.to_csv(\"webtretho2015_6.csv\", index=False, encoding=\"utf-8-sig\")\n","print(\"å·²æŠ“å–\", len(posts), \"æ¡å¸–å­ï¼Œä¿å­˜ä¸º webtretho_tag_rong_bien.csv\")\n"],"metadata":{"id":"w9JvA1gBJ2bU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!apt-get update > /dev/null\n","!apt-get install -y chromium chromium-driver > /dev/null\n","!pip install -q selenium\n"],"metadata":{"id":"311yZjPAKbMc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from selenium import webdriver\n","from selenium.webdriver.chrome.service import Service\n","from selenium.webdriver.chrome.options import Options\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import time\n","\n","# é…ç½® headless Chrome\n","chrome_options = Options()\n","chrome_options.add_argument(\"--headless\")\n","chrome_options.add_argument(\"--no-sandbox\")\n","chrome_options.add_argument(\"--disable-dev-shm-usage\")\n","chrome_options.binary_location = \"/usr/bin/chromium\"\n","\n","# åˆå§‹åŒ–æµè§ˆå™¨\n","driver = webdriver.Chrome(service=Service(\"/usr/lib/chromium/chromedriver\"), options=chrome_options)\n","\n","# æ‰“å¼€æ ‡ç­¾é¡µ\n","url = \"https://www.webtretho.com/tags/rong-bien\"\n","driver.get(url)\n","time.sleep(5)  # â³ ç­‰å¾…åŠ è½½å®Œæˆ\n","\n","soup = BeautifulSoup(driver.page_source, \"html.parser\")\n","driver.quit()\n","\n","# æå–å¸–å­å†…å®¹\n","posts = []\n","\n","for article in soup.find_all(\"div\", attrs={\"role\": \"article\"}):\n","    # æ ‡é¢˜\n","    title_tag = article.find(\"h4\")\n","    title = title_tag.get_text(strip=True) if title_tag else \"\"\n","\n","    # ä½œè€…\n","    author_tag = article.find(\"a\", class_=\"tw-font-bold text-main tw-text-xs\")\n","    author = author_tag.get_text(strip=True) if author_tag else \"\"\n","\n","    # æ—¥æœŸ\n","    date_tag = article.find(\"div\", class_=\"tw-text-xs text-gray-blue tw-mt-1.5\")\n","    date = date_tag.get_text(strip=True) if date_tag else \"\"\n","\n","    # å†…å®¹ï¼ˆæ­£æ–‡æ‘˜è¦ï¼‰\n","    content_tag = article.find(\"div\", class_=\"tw-leading-5 tw-text-sm text-black tw-whitespace-normal tw-break-words w-100 max-l-2\")\n","    content = content_tag.get_text(separator=\"\\n\", strip=True) if content_tag else \"\"\n","\n","    # é“¾æ¥\n","    link_tag = title_tag.find_parent(\"a\") if title_tag else None\n","    href = \"https://www.webtretho.com\" + link_tag[\"href\"] if link_tag and link_tag.has_attr(\"href\") else url\n","\n","    posts.append({\n","        \"title\": title,\n","        \"author\": author,\n","        \"date\": date,\n","        \"content\": content,\n","        \"link\": href\n","    })\n","\n","# ä¿å­˜ä¸º CSV\n","df = pd.DataFrame(posts)\n","df.to_csv(\"webtretho_tag_rong_bien.csv\", index=False, encoding=\"utf-8-sig\")\n","print(f\"æˆåŠŸæŠ“å– {len(posts)} æ¡å†…å®¹ï¼Œå·²ä¿å­˜ä¸º webtretho_tag_rong_bien.csv\")\n"],"metadata":{"id":"gnaWNSDEKVcO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"XiJ4vyOCVOxq"}}]}